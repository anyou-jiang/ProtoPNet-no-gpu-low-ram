{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "373e7e6c-daea-422d-b595-11caff0d6b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "import torch\n",
    "import torch.utils.data\n",
    "\n",
    "import argparse\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c08e071-09ae-4003-aac2-d956eaeb43d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## utility functions\n",
    "def makedir(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "def create_logger(log_filename, display=True):\n",
    "    f = open(log_filename, 'a')\n",
    "    counter = [0]\n",
    "    # this function will still have access to f after create_logger terminates\n",
    "    def logger(text):\n",
    "        if display:\n",
    "            print(text)\n",
    "        f.write(text + '\\n')\n",
    "        counter[0] += 1\n",
    "        if counter[0] % 10 == 0:\n",
    "            f.flush()\n",
    "            os.fsync(f.fileno())\n",
    "        # Question: do we need to flush()\n",
    "    return logger, f.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4bffefa-ef03-4e19-85aa-5fed7358dbca",
   "metadata": {},
   "outputs": [],
   "source": [
    "## setting\n",
    "prototype_shape = (128, 8, 1, 1)\n",
    "num_classes = 2\n",
    "prototype_activation_function = 'log'\n",
    "add_on_layers_type = 'regular'\n",
    "\n",
    "experiment_run = '003'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a539a78-f0b7-4ee9-9e25-e35691112f50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base_architecture: vgg19\n",
      "base_architecture_type: vgg\n",
      "mode_dir: ./saved_models/vgg19/003/\n",
      "saved main.ipynb to /home/jovyan/codes/ProtoPNet/main.ipynb\n",
      "train dir: ./datasets/cub200_cropped/train_cropped_augmented/\n",
      "test_dir: ./datasets/cub200_cropped/test_cropped/\n",
      "train_push_dir: ./datasets/cub200_cropped/train_cropped/\n"
     ]
    }
   ],
   "source": [
    "## settings\n",
    "base_architecture = 'vgg19'\n",
    "base_architecture_type = re.match('^[a-z]*', base_architecture).group(0)\n",
    "\n",
    "model_dir = './saved_models/' + base_architecture + '/' + experiment_run + '/'\n",
    "makedir(model_dir)\n",
    "\n",
    "my_filepath = os.path.join(os.getcwd(), 'main.ipynb') \n",
    "shutil.copy(src=my_filepath, dst=model_dir)\n",
    "\n",
    "log, logclose = create_logger(log_filename=os.path.join(model_dir, 'train.log'))\n",
    "img_dir = os.path.join(model_dir, 'img')\n",
    "makedir(img_dir)\n",
    "weight_matrix_filename = 'outputL_weights'\n",
    "prototype_img_filename_prefix = 'prototype-img'\n",
    "prototype_self_act_filename_prefix = 'prototype-self-act'\n",
    "proto_bound_boxes_filename_prefix = 'bb'\n",
    "\n",
    "log('base_architecture: {0}'.format(base_architecture))\n",
    "log('base_architecture_type: {0}'.format(base_architecture_type))\n",
    "log('mode_dir: {0}'.format(model_dir))\n",
    "log('saved main.ipynb to {0}'.format(my_filepath))\n",
    "\n",
    "data_path = './datasets/cub200_cropped/'\n",
    "train_dir = data_path + 'train_cropped_augmented/'\n",
    "test_dir = data_path + 'test_cropped/'\n",
    "train_push_dir = data_path + 'train_cropped/'\n",
    "\n",
    "log('train dir: {0}'.format(train_dir))\n",
    "log('test_dir: {0}'.format(test_dir))\n",
    "log('train_push_dir: {0}'.format(train_push_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0a13ed7-2725-4ea5-a807-5bb4da6ed39a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: training set size: 60\n",
      "INFO: push set size: 60\n",
      "INFO: test set size: 60\n",
      "INFO: batch size: 5\n"
     ]
    }
   ],
   "source": [
    "## load the dataset\n",
    "\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "img_size = 56\n",
    "train_batch_size = 5\n",
    "test_batch_size = 5\n",
    "train_push_batch_size = 5\n",
    "\n",
    "preprocess_mean = (0.485, 0.456, 0.406)\n",
    "preprocess_std = (0.229, 0.224, 0.225)\n",
    "\n",
    "normalize = transforms.Normalize(mean=preprocess_mean, std=preprocess_std)\n",
    "\n",
    "train_dataset = datasets.ImageFolder(\n",
    "    train_dir,\n",
    "    transforms.Compose([\n",
    "        transforms.Resize(size=(img_size, img_size)),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]))\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=train_batch_size, shuffle=True,\n",
    "    num_workers=0, pin_memory=False)\n",
    "# push set\n",
    "train_push_dataset = datasets.ImageFolder(\n",
    "    train_push_dir,\n",
    "    transforms.Compose([\n",
    "        transforms.Resize(size=(img_size, img_size)),\n",
    "        transforms.ToTensor(),\n",
    "    ]))\n",
    "train_push_loader = torch.utils.data.DataLoader(\n",
    "    train_push_dataset, batch_size=train_push_batch_size, shuffle=False,\n",
    "    num_workers=0, pin_memory=False)\n",
    "# test set\n",
    "test_dataset = datasets.ImageFolder(\n",
    "    test_dir,\n",
    "    transforms.Compose([\n",
    "        transforms.Resize(size=(img_size, img_size)),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]))\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset, batch_size=test_batch_size, shuffle=False,\n",
    "    num_workers=0, pin_memory=False)\n",
    "\n",
    "log('INFO: training set size: {0}'.format(len(train_loader.dataset)))\n",
    "log('INFO: push set size: {0}'.format(len(train_push_loader.dataset)))\n",
    "log('INFO: test set size: {0}'.format(len(test_loader.dataset)))\n",
    "log('INFO: batch size: {0}'.format(train_batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "600f91f4-fc3c-484c-8195-0424d0e6f54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## vgg_features\n",
    "import torch.nn as nn\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "\n",
    "class VGG_features(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super(VGG_features, self).__init__()\n",
    "        self.kernel_sizes = []\n",
    "        self.strides = []\n",
    "        self.paddings = []\n",
    "        self.features = self._make_layers(cfg)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        return x\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def _make_layers(self, cfg):\n",
    "        self.n_layers = 0\n",
    "        layers = []\n",
    "        in_channels = 3\n",
    "        for v in cfg:\n",
    "            if v == 'M':\n",
    "                layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "                self.kernel_sizes.append(2)\n",
    "                self.strides.append(2)\n",
    "                self.paddings.append(0)\n",
    "            else:\n",
    "                conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)\n",
    "                layers += [conv2d, nn.ReLU(inplace=True)]\n",
    "                self.n_layers += 1\n",
    "                self.kernel_sizes.append(3)\n",
    "                self.strides.append(1)\n",
    "                self.paddings.append(1)\n",
    "                in_channels = v\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def conv_info(self):\n",
    "        return self.kernel_sizes, self.strides, self.paddings\n",
    "\n",
    "    def num_layers(self):\n",
    "        '''\n",
    "        the number of conv layers in the network\n",
    "        '''\n",
    "        return self.n_layers\n",
    "\n",
    "    def __repr__(self):\n",
    "        template = 'VGG{}'\n",
    "        return template.format(self.num_layers() + 3)\n",
    "\n",
    "def vgg19_features():\n",
    "    \"\"\"VGG 19-layer model\n",
    "    \"\"\"\n",
    "    cfg = [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M']\n",
    "    model = VGG_features(cfg)\n",
    "    my_dict = model_zoo.load_url('https://download.pytorch.org/models/vgg19-dcbb9e9d.pth', model_dir='./pretrained_models')\n",
    "    keys_to_remove = set()\n",
    "    \n",
    "    for key in my_dict:\n",
    "        if key.startswith('classifier'):\n",
    "            keys_to_remove.add(key)\n",
    "    for key in keys_to_remove:\n",
    "        del my_dict[key]\n",
    "    model.load_state_dict(my_dict, strict=False)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1a3fb1b-132d-41d5-b0bd-22b3adcd5846",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def compute_proto_layer_rf_info_v2(img_size, layer_filter_sizes, layer_strides, layer_paddings, prototype_kernel_size):\n",
    "\n",
    "    assert(len(layer_filter_sizes) == len(layer_strides))\n",
    "    assert(len(layer_filter_sizes) == len(layer_paddings))\n",
    "\n",
    "    rf_info = [img_size, 1, 1, 0.5]\n",
    "\n",
    "    for i in range(len(layer_filter_sizes)):\n",
    "        filter_size = layer_filter_sizes[i]\n",
    "        stride_size = layer_strides[i]\n",
    "        padding_size = layer_paddings[i]\n",
    "\n",
    "        rf_info = compute_layer_rf_info(layer_filter_size=filter_size,\n",
    "                                layer_stride=stride_size,\n",
    "                                layer_padding=padding_size,\n",
    "                                previous_layer_rf_info=rf_info)\n",
    "\n",
    "    proto_layer_rf_info = compute_layer_rf_info(layer_filter_size=prototype_kernel_size,\n",
    "                                                layer_stride=1,\n",
    "                                                layer_padding='VALID',\n",
    "                                                previous_layer_rf_info=rf_info)\n",
    "\n",
    "    return proto_layer_rf_info\n",
    "\n",
    "def compute_layer_rf_info(layer_filter_size, layer_stride, layer_padding,\n",
    "                          previous_layer_rf_info):\n",
    "    n_in = previous_layer_rf_info[0] # input size\n",
    "    j_in = previous_layer_rf_info[1] # receptive field jump of input layer\n",
    "    r_in = previous_layer_rf_info[2] # receptive field size of input layer\n",
    "    start_in = previous_layer_rf_info[3] # center of receptive field of input layer\n",
    "\n",
    "    if layer_padding == 'SAME':\n",
    "        n_out = math.ceil(float(n_in) / float(layer_stride))\n",
    "        if (n_in % layer_stride == 0):\n",
    "            pad = max(layer_filter_size - layer_stride, 0)\n",
    "        else:\n",
    "            pad = max(layer_filter_size - (n_in % layer_stride), 0)\n",
    "        assert(n_out == math.floor((n_in - layer_filter_size + pad)/layer_stride) + 1) # sanity check\n",
    "        assert(pad == (n_out-1)*layer_stride - n_in + layer_filter_size) # sanity check\n",
    "    elif layer_padding == 'VALID':\n",
    "        n_out = math.ceil(float(n_in - layer_filter_size + 1) / float(layer_stride))\n",
    "        pad = 0\n",
    "        assert(n_out == math.floor((n_in - layer_filter_size + pad)/layer_stride) + 1) # sanity check\n",
    "        assert(pad == (n_out-1)*layer_stride - n_in + layer_filter_size) # sanity check\n",
    "    else:\n",
    "        # layer_padding is an int that is the amount of padding on one side\n",
    "        pad = layer_padding * 2\n",
    "        n_out = math.floor((n_in - layer_filter_size + pad)/layer_stride) + 1\n",
    "\n",
    "    pL = math.floor(pad/2)\n",
    "\n",
    "    j_out = j_in * layer_stride\n",
    "    r_out = r_in + (layer_filter_size - 1)*j_in\n",
    "    start_out = start_in + ((layer_filter_size - 1)/2 - pL)*j_in\n",
    "    return [n_out, j_out, r_out, start_out]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d6626c6-354c-46c6-b067-df80ed02c4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "import torch.nn.functional as F\n",
    "# from receptive_field import compute_proto_layer_rf_info_v2\n",
    "\n",
    "class PPNet(nn.Module):\n",
    "\n",
    "    def __init__(self, features, img_size, prototype_shape,\n",
    "                 proto_layer_rf_info, num_classes,\n",
    "                 prototype_activation_function='log',\n",
    "                 add_on_layers_type='bottleneck'):\n",
    "\n",
    "        super(PPNet, self).__init__()\n",
    "        self.img_size = img_size\n",
    "        self.prototype_shape = prototype_shape\n",
    "        self.num_prototypes = prototype_shape[0]\n",
    "        self.num_classes = num_classes\n",
    "        self.epsilon = 1e-4\n",
    "        \n",
    "        # prototype_activation_function could be 'log', 'linear',\n",
    "        # or a generic function that converts distance to similarity score\n",
    "        self.prototype_activation_function = prototype_activation_function\n",
    "\n",
    "        '''\n",
    "        Here we are initializing the class identities of the prototypes\n",
    "        Without domain specific knowledge we allocate the same number of\n",
    "        prototypes for each class\n",
    "        '''\n",
    "        assert(self.num_prototypes % self.num_classes == 0)\n",
    "        # a onehot indication matrix for each prototype's class identity\n",
    "        self.prototype_class_identity = torch.zeros(self.num_prototypes,\n",
    "                                                    self.num_classes)\n",
    "\n",
    "        num_prototypes_per_class = self.num_prototypes // self.num_classes\n",
    "        for j in range(self.num_prototypes):\n",
    "            self.prototype_class_identity[j, j // num_prototypes_per_class] = 1\n",
    "\n",
    "        self.proto_layer_rf_info = proto_layer_rf_info\n",
    "\n",
    "        # this has to be named features to allow the precise loading\n",
    "        self.features = features\n",
    "        first_add_on_layer_in_channels = [i for i in features.modules() if isinstance(i, nn.Conv2d)][-1].out_channels\n",
    "\n",
    "        self.add_on_layers = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=first_add_on_layer_in_channels, out_channels=self.prototype_shape[1], kernel_size=1),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(in_channels=self.prototype_shape[1], out_channels=self.prototype_shape[1], kernel_size=1),\n",
    "                nn.Sigmoid()\n",
    "                )\n",
    "        \n",
    "        self.prototype_vectors = nn.Parameter(torch.rand(self.prototype_shape),\n",
    "                                              requires_grad=True)\n",
    "\n",
    "        self.ones = nn.Parameter(torch.ones(self.prototype_shape),\n",
    "                                 requires_grad=False)\n",
    "\n",
    "        self.h_last_layer = nn.Linear(self.num_prototypes, self.num_classes,\n",
    "                                    bias=False) # do not use bias\n",
    "\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        f_out = self.f_conv_layer(x)\n",
    "        g_p_out, min_distances, _ = self.g_p_layer(f_out)\n",
    "        h_out = self.h_last_layer(g_p_out)\n",
    "        return h_out, min_distances    \n",
    "\n",
    "    def f_conv_layer(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.add_on_layers(x)\n",
    "        return x\n",
    "\n",
    "    def g_p_layer(self, z):\n",
    "        z2 = z ** 2\n",
    "        z2_patch_sum = F.conv2d(input=z2, weight=self.ones)\n",
    "\n",
    "        p2 = self.prototype_vectors ** 2\n",
    "        p2 = torch.sum(p2, dim=(1, 2, 3))\n",
    "        p2_reshape = p2.view(-1, 1, 1)\n",
    "\n",
    "        zp = F.conv2d(input=z, weight=self.prototype_vectors)\n",
    "        intermediate_result = - 2 * zp + p2_reshape\n",
    "        zp_distances = F.relu(z2_patch_sum + intermediate_result)\n",
    "\n",
    "        min_zp_distance = -F.max_pool2d(-zp_distances,\n",
    "                                      kernel_size=(zp_distances.size()[2],\n",
    "                                                   zp_distances.size()[3]))\n",
    "        min_zp_distance = min_zp_distance.view(-1, self.num_prototypes)\n",
    "        g_p_out = self.distance_2_similarity(min_zp_distance)        \n",
    "\n",
    "        return g_p_out, min_zp_distance, zp_distances\n",
    "\n",
    "    def distance_2_similarity(self, distances):\n",
    "        return torch.log((distances + 1) / (distances + self.epsilon))\n",
    "\n",
    "    def push_forward(self, x):\n",
    "        '''this method is needed for the pushing operation'''\n",
    "        f_out = self.f_conv_layer(x)\n",
    "        g_p_out, min_distances, distances = self.g_p_layer(f_out)\n",
    "        #return g_p_out, distances\n",
    "        return f_out, distances\n",
    "\n",
    "    def prune_prototypes(self, prototypes_to_prune):\n",
    "        '''\n",
    "        prototypes_to_prune: a list of indices each in\n",
    "        [0, current number of prototypes - 1] that indicates the prototypes to\n",
    "        be removed\n",
    "        '''\n",
    "        prototypes_to_keep = list(set(range(self.num_prototypes)) - set(prototypes_to_prune))\n",
    "\n",
    "        self.prototype_vectors = nn.Parameter(self.prototype_vectors.data[prototypes_to_keep, ...],\n",
    "                                              requires_grad=True)\n",
    "\n",
    "        self.prototype_shape = list(self.prototype_vectors.size())\n",
    "        self.num_prototypes = self.prototype_shape[0]\n",
    "\n",
    "        # changing self.h_last_layer in place\n",
    "        # changing in_features and out_features make sure the numbers are consistent\n",
    "        self.h_last_layer.in_features = self.num_prototypes\n",
    "        self.h_last_layer.out_features = self.num_classes\n",
    "        self.h_last_layer.weight.data = self.h_last_layer.weight.data[:, prototypes_to_keep]\n",
    "\n",
    "        # self.ones is nn.Parameter\n",
    "        self.ones = nn.Parameter(self.ones.data[prototypes_to_keep, ...],\n",
    "                                 requires_grad=False)\n",
    "        # self.prototype_class_identity is torch tensor\n",
    "        # so it does not need .data access for value update\n",
    "        self.prototype_class_identity = self.prototype_class_identity[prototypes_to_keep, :]\n",
    "\n",
    "    def __repr__(self):\n",
    "        # PPNet(self, features, img_size, prototype_shape,\n",
    "        # proto_layer_rf_info, num_classes, init_weights=True):\n",
    "        rep = (\n",
    "            'PPNet(\\n'\n",
    "            '\\tfeatures: {},\\n'\n",
    "            '\\timg_size: {},\\n'\n",
    "            '\\tprototype_shape: {},\\n'\n",
    "            '\\tproto_layer_rf_info: {},\\n'\n",
    "            '\\tnum_classes: {},\\n'\n",
    "            '\\tepsilon: {}\\n'\n",
    "            ')'\n",
    "        )\n",
    "\n",
    "        return rep.format(self.features,\n",
    "                          self.img_size,\n",
    "                          self.prototype_shape,\n",
    "                          self.proto_layer_rf_info,\n",
    "                          self.num_classes,\n",
    "                          self.epsilon)\n",
    "\n",
    "    def set_h_last_layer_incorrect_connection(self, incorrect_strength):\n",
    "        '''\n",
    "        the incorrect strength will be actual strength if -0.5 then input -0.5\n",
    "        '''\n",
    "        positive_one_weights_locations = torch.t(self.prototype_class_identity)\n",
    "        negative_one_weights_locations = 1 - positive_one_weights_locations\n",
    "\n",
    "        correct_class_connection = 1\n",
    "        incorrect_class_connection = incorrect_strength\n",
    "        self.h_last_layer.weight.data.copy_(\n",
    "            correct_class_connection * positive_one_weights_locations\n",
    "            + incorrect_class_connection * negative_one_weights_locations)\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.add_on_layers.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                # every init technique has an underscore _ in the name\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "\n",
    "        self.set_h_last_layer_incorrect_connection(incorrect_strength=-0.5)\n",
    "\n",
    "\n",
    "\n",
    "def construct_PPNet(base_architecture, pretrained, img_size,\n",
    "                    prototype_shape, num_classes,\n",
    "                    prototype_activation_function='log',\n",
    "                    add_on_layers_type='bottleneck'):\n",
    "    features = vgg19_features()\n",
    "    layer_filter_sizes, layer_strides, layer_paddings = features.conv_info()\n",
    "    proto_layer_rf_info = compute_proto_layer_rf_info_v2(img_size=img_size,\n",
    "                                                         layer_filter_sizes=layer_filter_sizes,\n",
    "                                                         layer_strides=layer_strides,\n",
    "                                                         layer_paddings=layer_paddings,\n",
    "                                                         prototype_kernel_size=prototype_shape[2])\n",
    "    return PPNet(features=features,\n",
    "                 img_size=img_size,\n",
    "                 prototype_shape=prototype_shape,\n",
    "                 proto_layer_rf_info=proto_layer_rf_info,\n",
    "                 num_classes=num_classes,\n",
    "                 prototype_activation_function=prototype_activation_function,\n",
    "                 add_on_layers_type=add_on_layers_type)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50439f05-39ae-4f10-9c87-6a8b251253a3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# construct the model\n",
    "ppnet = construct_PPNet(base_architecture=base_architecture,\n",
    "                              pretrained=True, img_size=img_size,\n",
    "                              prototype_shape=prototype_shape,\n",
    "                              num_classes=num_classes,\n",
    "                              prototype_activation_function=prototype_activation_function,\n",
    "                              add_on_layers_type=add_on_layers_type)\n",
    "\n",
    "warm_optimizer_lrs = {'add_on_layers': 3e-3, \n",
    "                      'prototype_vectors': 3e-3}\n",
    "\n",
    "warm_optimizer_specs = [{\n",
    "    'params': ppnet.add_on_layers.parameters(), \n",
    "    'lr': warm_optimizer_lrs['add_on_layers'], \n",
    "    'weight_decay': 1e-3},                     \n",
    "    {'params': ppnet.prototype_vectors, \n",
    "    'lr': warm_optimizer_lrs['prototype_vectors']\n",
    "    }]\n",
    "\n",
    "warm_optimizer = torch.optim.Adam(warm_optimizer_specs)\n",
    "\n",
    "joint_optimizer_lrs = {'features': 1e-4,\n",
    "                       'add_on_layers': 3e-3,\n",
    "                       'prototype_vectors': 3e-3}\n",
    "joint_lr_step_size = 5\n",
    "\n",
    "joint_optimizer_specs = [{\n",
    "    'params': ppnet.features.parameters(), \n",
    "    'lr': joint_optimizer_lrs['features'], \n",
    "    'weight_decay': 1e-3\n",
    "    }, \n",
    "    {\n",
    "    'params': ppnet.add_on_layers.parameters(), \n",
    "    'lr': joint_optimizer_lrs['add_on_layers'], \n",
    "    'weight_decay': 1e-3 },\n",
    "    {\n",
    "    'params': ppnet.prototype_vectors,\n",
    "    'lr': joint_optimizer_lrs['prototype_vectors']\n",
    "    }]\n",
    "\n",
    "joint_optimizer = torch.optim.Adam(joint_optimizer_specs)\n",
    "\n",
    "joint_lr_scheduler = torch.optim.lr_scheduler.StepLR(joint_optimizer, step_size=joint_lr_step_size, gamma=0.1)\n",
    "\n",
    "h_last_layer_optimizer_lr = 1e-4\n",
    "\n",
    "h_last_layer_optimizer_specs = [{\n",
    "    'params': ppnet.h_last_layer.parameters(), \n",
    "    'lr': h_last_layer_optimizer_lr\n",
    "    }]\n",
    "\n",
    "h_last_layer_optimizer = torch.optim.Adam(h_last_layer_optimizer_specs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a224a04b-b253-4223-b6a0-944c9236d121",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "\n",
    "def _train_or_test(model, dataloader, optimizer, class_specific, coefs, log):\n",
    "    is_train = optimizer is not None\n",
    "    start = time.time()\n",
    "    n_examples = 0\n",
    "    n_correct = 0\n",
    "    n_batches = 0\n",
    "    total_cross_entropy = 0\n",
    "    total_cluster_cost = 0\n",
    "    total_separation_cost = 0\n",
    "    total_avg_separation_cost = 0\n",
    "\n",
    "    for i, (image, label) in enumerate(dataloader):\n",
    "        input_imag = image \n",
    "        target_class = label\n",
    "        log('INFO: training with the images batch#{0}'.format(i))\n",
    "        grad_req = torch.enable_grad() if is_train else torch.no_grad()\n",
    "        with grad_req:\n",
    "            output, min_distances = model(input_imag)\n",
    "            # compute loss\n",
    "            cross_entropy = torch.nn.functional.cross_entropy(output, target_class)\n",
    "\n",
    "            max_dist = (ppnet.prototype_shape[1] * ppnet.prototype_shape[2] * ppnet.prototype_shape[3])\n",
    "\n",
    "            correct_class_indicators = torch.t(ppnet.prototype_class_identity[:, target_class]) # batch_size * num_prototypes\n",
    "            inverted_min_distances2correct_class, _ = torch.max((max_dist - min_distances) * correct_class_indicators, dim=1)  # max over all correct prototypes\n",
    "            cluster_cost = torch.mean(max_dist - inverted_min_distances2correct_class)\n",
    "\n",
    "            # calculate separation cost\n",
    "            wrong_class_indicators = 1 - correct_class_indicators\n",
    "            inverted_min_distances2wrong_class, _ = torch.max((max_dist - min_distances) * wrong_class_indicators, dim=1)\n",
    "            separation_cost = torch.mean(max_dist - inverted_min_distances2wrong_class)\n",
    "\n",
    "            # calculate avg cluster cost\n",
    "            avg_separation_cost = torch.sum(min_distances * wrong_class_indicators, dim=1) / torch.sum(wrong_class_indicators, dim=1)\n",
    "            avg_separation_cost = torch.mean(avg_separation_cost)\n",
    "                \n",
    "            l1_mask = 1 - torch.t(ppnet.prototype_class_identity) \n",
    "            l1 = (ppnet.h_last_layer.weight * l1_mask).norm(p=1)\n",
    "\n",
    "            # evaluation statistics\n",
    "            _, predicted = torch.max(output.data, dim=1)\n",
    "            n_examples += target_class.size(0)\n",
    "            n_correct += (predicted == target_class).sum().item()\n",
    "\n",
    "            n_batches += 1\n",
    "            total_cross_entropy += cross_entropy.item()\n",
    "            total_cluster_cost += cluster_cost.item()\n",
    "            total_separation_cost += separation_cost.item()\n",
    "            total_avg_separation_cost += avg_separation_cost.item()\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        if is_train:\n",
    "            loss = (coefs['crs_ent'] * cross_entropy + coefs['clst'] * cluster_cost + coefs['sep'] * separation_cost + coefs['l1'] * l1)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        del input_imag\n",
    "        del target_class\n",
    "        del output\n",
    "        del predicted\n",
    "        del min_distances\n",
    "\n",
    "    end = time.time()\n",
    "    training_or_testing = 'training' if is_train else 'testing'\n",
    "    log('INFO: {} time: \\t{}'.format(training_or_testing, end -  start))\n",
    "    log('INFO: average cross entropy per batch: \\t{0}'.format(total_cross_entropy / n_batches))\n",
    "    log('INFO: average cluster loss per batch: \\t{0}'.format(total_cluster_cost / n_batches))\n",
    "    log('INFO: separation loss:\\t{0}'.format(total_separation_cost / n_batches))\n",
    "    log('INFO: avged separation loss:\\t{0}'.format(total_avg_separation_cost / n_batches))\n",
    "    log('INFO: accu: \\t{0}%'.format(n_correct / n_examples * 100))\n",
    "    \n",
    "    return n_correct / n_examples\n",
    "\n",
    "\n",
    "def tnt_train(model, dataloader, optimizer, class_specific, coefs, log):\n",
    "    assert(optimizer is not None)    \n",
    "    model.train()\n",
    "    return _train_or_test(model=model, dataloader=dataloader, optimizer=optimizer,\n",
    "                          class_specific=class_specific, coefs=coefs, log=log)\n",
    "\n",
    "\n",
    "def tnt_test(model, dataloader, class_specific, log):\n",
    "    model.eval()\n",
    "    return _train_or_test(model=model, dataloader=dataloader, optimizer=None,\n",
    "                          class_specific=class_specific, coefs=None, log=log)\n",
    "\n",
    "\n",
    "def tnt_last_only(model, log=print):\n",
    "    for p in ppnet.features.parameters():\n",
    "        p.requires_grad = False\n",
    "    for p in ppnet.add_on_layers.parameters():\n",
    "        p.requires_grad = False\n",
    "    ppnet.prototype_vectors.requires_grad = False\n",
    "    for p in ppnet.h_last_layer.parameters():\n",
    "        p.requires_grad = True\n",
    "\n",
    "def tnt_warm_only(model, log=print):\n",
    "    for p in ppnet.features.parameters():\n",
    "        p.requires_grad = False\n",
    "    for p in ppnet.add_on_layers.parameters():\n",
    "        p.requires_grad = True\n",
    "    ppnet.prototype_vectors.requires_grad = True\n",
    "    for p in ppnet.h_last_layer.parameters():\n",
    "        p.requires_grad = True\n",
    "    \n",
    "\n",
    "def tnt_joint(model, log=print):\n",
    "    for p in ppnet.features.parameters():\n",
    "        p.requires_grad = True\n",
    "    for p in ppnet.add_on_layers.parameters():\n",
    "        p.requires_grad = True\n",
    "    ppnet.prototype_vectors.requires_grad = True\n",
    "    for p in ppnet.h_last_layer.parameters():\n",
    "        p.requires_grad = True\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c6f40521-f6c6-41e3-b357-b8b029d771a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_rf_prototype(img_size, prototype_patch_index, protoL_rf_info):\n",
    "    img_index = prototype_patch_index[0]\n",
    "    height_index = prototype_patch_index[1]\n",
    "    width_index = prototype_patch_index[2]\n",
    "    rf_indices = compute_rf_protoL_at_spatial_location(img_size,\n",
    "                                                       height_index,\n",
    "                                                       width_index,\n",
    "                                                       protoL_rf_info)\n",
    "    return [img_index, rf_indices[0], rf_indices[1],\n",
    "            rf_indices[2], rf_indices[3]]\n",
    "\n",
    "def compute_rf_protoL_at_spatial_location(img_size, height_index, width_index, protoL_rf_info):\n",
    "    n = protoL_rf_info[0]\n",
    "    j = protoL_rf_info[1]\n",
    "    r = protoL_rf_info[2]\n",
    "    start = protoL_rf_info[3]\n",
    "    assert(height_index < n)\n",
    "    assert(width_index < n)\n",
    "\n",
    "    center_h = start + (height_index*j)\n",
    "    center_w = start + (width_index*j)\n",
    "\n",
    "    rf_start_height_index = max(int(center_h - (r/2)), 0)\n",
    "    rf_end_height_index = min(int(center_h + (r/2)), img_size)\n",
    "\n",
    "    rf_start_width_index = max(int(center_w - (r/2)), 0)\n",
    "    rf_end_width_index = min(int(center_w + (r/2)), img_size)\n",
    "\n",
    "    return [rf_start_height_index, rf_end_height_index,\n",
    "            rf_start_width_index, rf_end_width_index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c8bb2522-2067-4e5a-982c-bf7f018aeb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import copy\n",
    "import time\n",
    "\n",
    "# from receptive_field import compute_rf_prototype\n",
    "# from helpers import makedir, find_high_activation_crop\n",
    "\n",
    "def preprocess(x, mean, std):\n",
    "    assert x.size(1) == 3\n",
    "    y = torch.zeros_like(x)\n",
    "    for i in range(3):\n",
    "        y[:, i, :, :] = (x[:, i, :, :] - mean[i]) / std[i]\n",
    "    return y\n",
    "\n",
    "\n",
    "def preprocess_input_function(x):\n",
    "    '''\n",
    "    allocate new tensor like x and apply the normalization used in the\n",
    "    pretrained model\n",
    "    '''\n",
    "    return preprocess(x, mean=preprocess_mean, std=preprocess_std)\n",
    "\n",
    "def find_high_activation_crop(activation_map, percentile=95):\n",
    "    threshold = np.percentile(activation_map, percentile)\n",
    "    mask = np.ones(activation_map.shape)\n",
    "    mask[activation_map < threshold] = 0\n",
    "    lower_y, upper_y, lower_x, upper_x = 0, 0, 0, 0\n",
    "    for i in range(mask.shape[0]):\n",
    "        if np.amax(mask[i]) > 0.5:\n",
    "            lower_y = i\n",
    "            break\n",
    "    for i in reversed(range(mask.shape[0])):\n",
    "        if np.amax(mask[i]) > 0.5:\n",
    "            upper_y = i\n",
    "            break\n",
    "    for j in range(mask.shape[1]):\n",
    "        if np.amax(mask[:,j]) > 0.5:\n",
    "            lower_x = j\n",
    "            break\n",
    "    for j in reversed(range(mask.shape[1])):\n",
    "        if np.amax(mask[:,j]) > 0.5:\n",
    "            upper_x = j\n",
    "            break\n",
    "    return lower_y, upper_y+1, lower_x, upper_x+1\n",
    "\n",
    "# push each prototype to the nearest patch in the training set\n",
    "def push_prototypes(dataloader, # pytorch dataloader (must be unnormalized in [0,1])\n",
    "                    prototype_network, # pytorch network with prototype_vectors\n",
    "                    class_specific=True,\n",
    "                    preprocess_input_function=None, # normalize if needed\n",
    "                    prototype_layer_stride=1,\n",
    "                    root_dir_for_saving_prototypes=None, # if not None, prototypes will be saved here\n",
    "                    epoch_number=None, # if not provided, prototypes saved previously will be overwritten\n",
    "                    prototype_img_filename_prefix=None,\n",
    "                    prototype_self_act_filename_prefix=None,\n",
    "                    proto_bound_boxes_filename_prefix=None,\n",
    "                    save_prototype_class_identity=True, # which class the prototype image comes from\n",
    "                    log=print,\n",
    "                    prototype_activation_function_in_numpy=None):\n",
    "\n",
    "    prototype_network.eval()\n",
    "\n",
    "    prototype_shape = prototype_network.prototype_shape\n",
    "    n_prototypes = prototype_network.num_prototypes\n",
    "    # saves the closest distance seen so far\n",
    "    global_min_proto_dist = np.full(n_prototypes, np.inf)\n",
    "    # saves the patch representation that gives the current smallest distance\n",
    "    global_min_fmap_patches = np.zeros(\n",
    "        [n_prototypes,\n",
    "         prototype_shape[1],\n",
    "         prototype_shape[2],\n",
    "         prototype_shape[3]])\n",
    "\n",
    "    '''\n",
    "    proto_rf_boxes and proto_bound_boxes column:\n",
    "    0: image index in the entire dataset\n",
    "    1: height start index\n",
    "    2: height end index\n",
    "    3: width start index\n",
    "    4: width end index\n",
    "    5: (optional) class identity\n",
    "    '''\n",
    "\n",
    "    proto_rf_boxes = np.full(shape=[n_prototypes, 6], fill_value=-1)\n",
    "    proto_bound_boxes = np.full(shape=[n_prototypes, 6], fill_value=-1)\n",
    "\n",
    "    proto_epoch_dir = os.path.join(root_dir_for_saving_prototypes, 'epoch-'+str(epoch_number))\n",
    "    makedir(proto_epoch_dir)\n",
    "\n",
    "    search_batch_size = dataloader.batch_size\n",
    "    num_classes = prototype_network.num_classes\n",
    "\n",
    "    for push_iter, (search_batch_input, search_y) in enumerate(dataloader):\n",
    "        start_index_of_search_batch = push_iter * search_batch_size\n",
    "        update_prototypes_on_batch(search_batch_input,\n",
    "                                   start_index_of_search_batch,\n",
    "                                   prototype_network,\n",
    "                                   global_min_proto_dist,\n",
    "                                   global_min_fmap_patches,\n",
    "                                   proto_rf_boxes,\n",
    "                                   proto_bound_boxes,\n",
    "                                   class_specific=class_specific,\n",
    "                                   search_y=search_y,\n",
    "                                   num_classes=num_classes,\n",
    "                                   preprocess_input_function=preprocess_input_function,\n",
    "                                   prototype_layer_stride=prototype_layer_stride,\n",
    "                                   dir_for_saving_prototypes=proto_epoch_dir,\n",
    "                                   prototype_img_filename_prefix=prototype_img_filename_prefix,\n",
    "                                   prototype_self_act_filename_prefix=prototype_self_act_filename_prefix,\n",
    "                                   prototype_activation_function_in_numpy=prototype_activation_function_in_numpy)\n",
    "\n",
    "    np.save(os.path.join(proto_epoch_dir, proto_bound_boxes_filename_prefix + '-receptive_field' + str(epoch_number) + '.npy'), proto_rf_boxes)\n",
    "    np.save(os.path.join(proto_epoch_dir, proto_bound_boxes_filename_prefix + str(epoch_number) + '.npy'), proto_bound_boxes)\n",
    "\n",
    "    prototype_update = np.reshape(global_min_fmap_patches, tuple(prototype_shape))\n",
    "    prototype_network.prototype_vectors.data.copy_(torch.tensor(prototype_update, dtype=torch.float32))\n",
    "\n",
    "# update each prototype for current search batch\n",
    "def update_prototypes_on_batch(search_batch_input,\n",
    "                               start_index_of_search_batch,\n",
    "                               prototype_network,\n",
    "                               global_min_proto_dist, # this will be updated\n",
    "                               global_min_fmap_patches, # this will be updated\n",
    "                               proto_rf_boxes, # this will be updated\n",
    "                               proto_bound_boxes, # this will be updated\n",
    "                               class_specific=True,\n",
    "                               search_y=None, # required if class_specific == True\n",
    "                               num_classes=None, # required if class_specific == True\n",
    "                               preprocess_input_function=None,\n",
    "                               prototype_layer_stride=1,\n",
    "                               dir_for_saving_prototypes=None,\n",
    "                               prototype_img_filename_prefix=None,\n",
    "                               prototype_self_act_filename_prefix=None,\n",
    "                               prototype_activation_function_in_numpy=None):\n",
    "\n",
    "    prototype_network.eval()\n",
    "    search_batch = preprocess_input_function(search_batch_input)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        protoL_input_tmp, proto_dist_tmp = prototype_network.push_forward(search_batch)\n",
    "\n",
    "    protoL_input_ = protoL_input_tmp.numpy()\n",
    "    proto_dist_ = proto_dist_tmp.numpy()\n",
    "    \n",
    "    class_to_img_index_dict = {key: [] for key in range(num_classes)}\n",
    "    # img_y is the image's integer label\n",
    "    for img_index, img_y in enumerate(search_y):\n",
    "        img_label = img_y.item()\n",
    "        class_to_img_index_dict[img_label].append(img_index)\n",
    "\n",
    "    prototype_shape = prototype_network.prototype_shape\n",
    "    n_prototypes = prototype_shape[0]\n",
    "    proto_h = prototype_shape[2]\n",
    "    proto_w = prototype_shape[3]\n",
    "    max_dist = prototype_shape[1] * prototype_shape[2] * prototype_shape[3]\n",
    "\n",
    "    for j in range(n_prototypes):\n",
    "        target_class = torch.argmax(prototype_network.prototype_class_identity[j]).item()\n",
    "        if len(class_to_img_index_dict[target_class]) == 0:\n",
    "            continue\n",
    "        proto_dist_j = proto_dist_[class_to_img_index_dict[target_class]][:,j,:,:]\n",
    "\n",
    "        batch_min_proto_dist_j = np.amin(proto_dist_j)\n",
    "        if batch_min_proto_dist_j < global_min_proto_dist[j]:\n",
    "            batch_argmin_proto_dist_j = list(np.unravel_index(np.argmin(proto_dist_j, axis=None), proto_dist_j.shape))\n",
    "\n",
    "            ''' change the argmin index from the index among images of the target class to the index in the entire search batch '''\n",
    "            batch_argmin_proto_dist_j[0] = class_to_img_index_dict[target_class][batch_argmin_proto_dist_j[0]]\n",
    "\n",
    "            # retrieve the corresponding feature map patch\n",
    "            img_index_in_batch = batch_argmin_proto_dist_j[0]\n",
    "            fmap_height_start_index = batch_argmin_proto_dist_j[1] * prototype_layer_stride\n",
    "            fmap_height_end_index = fmap_height_start_index + proto_h\n",
    "            fmap_width_start_index = batch_argmin_proto_dist_j[2] * prototype_layer_stride\n",
    "            fmap_width_end_index = fmap_width_start_index + proto_w\n",
    "\n",
    "            batch_min_fmap_patch_j = protoL_input_[img_index_in_batch, :,\n",
    "                                                   fmap_height_start_index:fmap_height_end_index,\n",
    "                                                   fmap_width_start_index:fmap_width_end_index]\n",
    "\n",
    "            global_min_proto_dist[j] = batch_min_proto_dist_j\n",
    "            global_min_fmap_patches[j] = batch_min_fmap_patch_j\n",
    "            \n",
    "            # get the receptive field boundary of the image patch that generates the representation\n",
    "            protoL_rf_info = prototype_network.proto_layer_rf_info\n",
    "            rf_prototype_j = compute_rf_prototype(search_batch.size(2), batch_argmin_proto_dist_j, protoL_rf_info)\n",
    "            \n",
    "            # get the whole image\n",
    "            original_img_j = search_batch_input[rf_prototype_j[0]]\n",
    "            original_img_j = original_img_j.numpy()\n",
    "            original_img_j = np.transpose(original_img_j, (1, 2, 0))\n",
    "            original_img_size = original_img_j.shape[0]\n",
    "            \n",
    "            # crop out the receptive field\n",
    "            rf_img_j = original_img_j[rf_prototype_j[1]:rf_prototype_j[2],\n",
    "                                      rf_prototype_j[3]:rf_prototype_j[4], :]\n",
    "            \n",
    "            # save the prototype receptive field information\n",
    "            proto_rf_boxes[j, 0] = rf_prototype_j[0] + start_index_of_search_batch\n",
    "            proto_rf_boxes[j, 1] = rf_prototype_j[1]\n",
    "            proto_rf_boxes[j, 2] = rf_prototype_j[2]\n",
    "            proto_rf_boxes[j, 3] = rf_prototype_j[3]\n",
    "            proto_rf_boxes[j, 4] = rf_prototype_j[4]\n",
    "            if proto_rf_boxes.shape[1] == 6 and search_y is not None:\n",
    "                proto_rf_boxes[j, 5] = search_y[rf_prototype_j[0]].item()\n",
    "\n",
    "            # find the highly activated region of the original image\n",
    "            proto_dist_img_j = proto_dist_[img_index_in_batch, j, :, :]\n",
    "            if prototype_network.prototype_activation_function == 'log':\n",
    "                proto_act_img_j = np.log((proto_dist_img_j + 1) / (proto_dist_img_j + prototype_network.epsilon))\n",
    "            elif prototype_network.prototype_activation_function == 'linear':\n",
    "                proto_act_img_j = max_dist - proto_dist_img_j\n",
    "            else:\n",
    "                proto_act_img_j = prototype_activation_function_in_numpy(proto_dist_img_j)\n",
    "            upsampled_act_img_j = cv2.resize(proto_act_img_j, dsize=(original_img_size, original_img_size),\n",
    "                                             interpolation=cv2.INTER_CUBIC)\n",
    "            proto_bound_j = find_high_activation_crop(upsampled_act_img_j)\n",
    "            # crop out the image patch with high activation as prototype image\n",
    "            proto_img_j = original_img_j[proto_bound_j[0]:proto_bound_j[1],\n",
    "                                         proto_bound_j[2]:proto_bound_j[3], :]\n",
    "\n",
    "            # save the prototype boundary (rectangular boundary of highly activated region)\n",
    "            proto_bound_boxes[j, 0] = proto_rf_boxes[j, 0]\n",
    "            proto_bound_boxes[j, 1] = proto_bound_j[0]\n",
    "            proto_bound_boxes[j, 2] = proto_bound_j[1]\n",
    "            proto_bound_boxes[j, 3] = proto_bound_j[2]\n",
    "            proto_bound_boxes[j, 4] = proto_bound_j[3]\n",
    "            if proto_bound_boxes.shape[1] == 6 and search_y is not None:\n",
    "                proto_bound_boxes[j, 5] = search_y[rf_prototype_j[0]].item()\n",
    "\n",
    "    del class_to_img_index_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "84ac8e6a-9bfc-4b90-b1df-dc003711f0ee",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: start training the model ......\n",
      "INFO:epoch: \t0\n",
      "INFO: training with the images batch#0\n",
      "INFO: training with the images batch#1\n",
      "INFO: training with the images batch#2\n",
      "INFO: training with the images batch#3\n",
      "INFO: training with the images batch#4\n",
      "INFO: training with the images batch#5\n",
      "INFO: training with the images batch#6\n",
      "INFO: training with the images batch#7\n",
      "INFO: training with the images batch#8\n",
      "INFO: training with the images batch#9\n",
      "INFO: training with the images batch#10\n",
      "INFO: training with the images batch#11\n",
      "INFO: training time: \t2.9157440662384033\n",
      "INFO: average cross entropy per batch: \t0.8079073280096054\n",
      "INFO: average cluster loss per batch: \t0.8237993468840917\n",
      "INFO: separation loss:\t0.8235770414272944\n",
      "INFO: avged separation loss:\t2.5115922689437866\n",
      "INFO: accu: \t55.00000000000001%\n",
      "INFO: training with the images batch#0\n",
      "INFO: training with the images batch#1\n",
      "INFO: training with the images batch#2\n",
      "INFO: training with the images batch#3\n",
      "INFO: training with the images batch#4\n",
      "INFO: training with the images batch#5\n",
      "INFO: training with the images batch#6\n",
      "INFO: training with the images batch#7\n",
      "INFO: training with the images batch#8\n",
      "INFO: training with the images batch#9\n",
      "INFO: training with the images batch#10\n",
      "INFO: training with the images batch#11\n",
      "INFO: testing time: \t2.272254228591919\n",
      "INFO: average cross entropy per batch: \t0.6777733912070593\n",
      "INFO: average cluster loss per batch: \t0.8491383045911789\n",
      "INFO: separation loss:\t0.9383500218391418\n",
      "INFO: avged separation loss:\t2.5901148120562234\n",
      "INFO: accu: \t61.66666666666667%\n",
      "INFO:epoch: \t1\n",
      "INFO: training with the images batch#0\n",
      "INFO: training with the images batch#1\n",
      "INFO: training with the images batch#2\n",
      "INFO: training with the images batch#3\n",
      "INFO: training with the images batch#4\n",
      "INFO: training with the images batch#5\n",
      "INFO: training with the images batch#6\n",
      "INFO: training with the images batch#7\n",
      "INFO: training with the images batch#8\n",
      "INFO: training with the images batch#9\n",
      "INFO: training with the images batch#10\n",
      "INFO: training with the images batch#11\n",
      "INFO: training time: \t2.3123083114624023\n",
      "INFO: average cross entropy per batch: \t0.5625792692104975\n",
      "INFO: average cluster loss per batch: \t0.7503675520420074\n",
      "INFO: separation loss:\t0.8600301742553711\n",
      "INFO: avged separation loss:\t2.5519111156463623\n",
      "INFO: accu: \t66.66666666666666%\n",
      "INFO: training with the images batch#0\n",
      "INFO: training with the images batch#1\n",
      "INFO: training with the images batch#2\n",
      "INFO: training with the images batch#3\n",
      "INFO: training with the images batch#4\n",
      "INFO: training with the images batch#5\n",
      "INFO: training with the images batch#6\n",
      "INFO: training with the images batch#7\n",
      "INFO: training with the images batch#8\n",
      "INFO: training with the images batch#9\n",
      "INFO: training with the images batch#10\n",
      "INFO: training with the images batch#11\n",
      "INFO: testing time: \t2.2951393127441406\n",
      "INFO: average cross entropy per batch: \t0.6746915305654207\n",
      "INFO: average cluster loss per batch: \t0.8212608645359675\n",
      "INFO: separation loss:\t0.9296982983748118\n",
      "INFO: avged separation loss:\t2.5817761619885764\n",
      "INFO: accu: \t58.333333333333336%\n",
      "INFO:epoch: \t2\n",
      "INFO: training with the images batch#0\n",
      "INFO: training with the images batch#1\n",
      "INFO: training with the images batch#2\n",
      "INFO: training with the images batch#3\n",
      "INFO: training with the images batch#4\n",
      "INFO: training with the images batch#5\n",
      "INFO: training with the images batch#6\n",
      "INFO: training with the images batch#7\n",
      "INFO: training with the images batch#8\n",
      "INFO: training with the images batch#9\n",
      "INFO: training with the images batch#10\n",
      "INFO: training with the images batch#11\n",
      "INFO: training time: \t2.177748680114746\n",
      "INFO: average cross entropy per batch: \t0.49491965025663376\n",
      "INFO: average cluster loss per batch: \t0.6860188245773315\n",
      "INFO: separation loss:\t0.8455718805392584\n",
      "INFO: avged separation loss:\t2.554205298423767\n",
      "INFO: accu: \t75.0%\n",
      "INFO: training with the images batch#0\n",
      "INFO: training with the images batch#1\n",
      "INFO: training with the images batch#2\n",
      "INFO: training with the images batch#3\n",
      "INFO: training with the images batch#4\n",
      "INFO: training with the images batch#5\n",
      "INFO: training with the images batch#6\n",
      "INFO: training with the images batch#7\n",
      "INFO: training with the images batch#8\n",
      "INFO: training with the images batch#9\n",
      "INFO: training with the images batch#10\n",
      "INFO: training with the images batch#11\n",
      "INFO: testing time: \t2.1496403217315674\n",
      "INFO: average cross entropy per batch: \t0.7161528766155243\n",
      "INFO: average cluster loss per batch: \t0.8182097723086675\n",
      "INFO: separation loss:\t0.8894138336181641\n",
      "INFO: avged separation loss:\t2.6031821171442666\n",
      "INFO: accu: \t58.333333333333336%\n",
      "INFO:epoch: \t3\n",
      "INFO: training with the images batch#0\n",
      "INFO: training with the images batch#1\n",
      "INFO: training with the images batch#2\n",
      "INFO: training with the images batch#3\n",
      "INFO: training with the images batch#4\n",
      "INFO: training with the images batch#5\n",
      "INFO: training with the images batch#6\n",
      "INFO: training with the images batch#7\n",
      "INFO: training with the images batch#8\n",
      "INFO: training with the images batch#9\n",
      "INFO: training with the images batch#10\n",
      "INFO: training with the images batch#11\n",
      "INFO: training time: \t2.2203845977783203\n",
      "INFO: average cross entropy per batch: \t0.4442039653658867\n",
      "INFO: average cluster loss per batch: \t0.6314155807097753\n",
      "INFO: separation loss:\t0.8464303811391195\n",
      "INFO: avged separation loss:\t2.557732800642649\n",
      "INFO: accu: \t80.0%\n",
      "INFO: training with the images batch#0\n",
      "INFO: training with the images batch#1\n",
      "INFO: training with the images batch#2\n",
      "INFO: training with the images batch#3\n",
      "INFO: training with the images batch#4\n",
      "INFO: training with the images batch#5\n",
      "INFO: training with the images batch#6\n",
      "INFO: training with the images batch#7\n",
      "INFO: training with the images batch#8\n",
      "INFO: training with the images batch#9\n",
      "INFO: training with the images batch#10\n",
      "INFO: training with the images batch#11\n",
      "INFO: testing time: \t2.3427441120147705\n",
      "INFO: average cross entropy per batch: \t0.7121126651763916\n",
      "INFO: average cluster loss per batch: \t0.7724358588457108\n",
      "INFO: separation loss:\t0.8778333961963654\n",
      "INFO: avged separation loss:\t2.5935808618863425\n",
      "INFO: accu: \t61.66666666666667%\n",
      "INFO:epoch: \t4\n",
      "INFO: training with the images batch#0\n",
      "INFO: training with the images batch#1\n",
      "INFO: training with the images batch#2\n",
      "INFO: training with the images batch#3\n",
      "INFO: training with the images batch#4\n",
      "INFO: training with the images batch#5\n",
      "INFO: training with the images batch#6\n",
      "INFO: training with the images batch#7\n",
      "INFO: training with the images batch#8\n",
      "INFO: training with the images batch#9\n",
      "INFO: training with the images batch#10\n",
      "INFO: training with the images batch#11\n",
      "INFO: training time: \t2.157383680343628\n",
      "INFO: average cross entropy per batch: \t0.41100597009062767\n",
      "INFO: average cluster loss per batch: \t0.5969454199075699\n",
      "INFO: separation loss:\t0.8444951772689819\n",
      "INFO: avged separation loss:\t2.5439772605895996\n",
      "INFO: accu: \t81.66666666666667%\n",
      "INFO: training with the images batch#0\n",
      "INFO: training with the images batch#1\n",
      "INFO: training with the images batch#2\n",
      "INFO: training with the images batch#3\n",
      "INFO: training with the images batch#4\n",
      "INFO: training with the images batch#5\n",
      "INFO: training with the images batch#6\n",
      "INFO: training with the images batch#7\n",
      "INFO: training with the images batch#8\n",
      "INFO: training with the images batch#9\n",
      "INFO: training with the images batch#10\n",
      "INFO: training with the images batch#11\n",
      "INFO: testing time: \t2.181607484817505\n",
      "INFO: average cross entropy per batch: \t0.7005876898765564\n",
      "INFO: average cluster loss per batch: \t0.747298980752627\n",
      "INFO: separation loss:\t0.860629012187322\n",
      "INFO: avged separation loss:\t2.586413323879242\n",
      "INFO: accu: \t63.33333333333333%\n",
      "INFO:epoch: \t5\n",
      "INFO: training with the images batch#0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:182: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: training with the images batch#1\n",
      "INFO: training with the images batch#2\n",
      "INFO: training with the images batch#3\n",
      "INFO: training with the images batch#4\n",
      "INFO: training with the images batch#5\n",
      "INFO: training with the images batch#6\n",
      "INFO: training with the images batch#7\n",
      "INFO: training with the images batch#8\n",
      "INFO: training with the images batch#9\n",
      "INFO: training with the images batch#10\n",
      "INFO: training with the images batch#11\n",
      "INFO: training time: \t7.823610782623291\n",
      "INFO: average cross entropy per batch: \t0.9311062668760618\n",
      "INFO: average cluster loss per batch: \t0.652057888607184\n",
      "INFO: separation loss:\t0.7447778185208639\n",
      "INFO: avged separation loss:\t2.4589456717173257\n",
      "INFO: accu: \t53.333333333333336%\n",
      "INFO: training with the images batch#0\n",
      "INFO: training with the images batch#1\n",
      "INFO: training with the images batch#2\n",
      "INFO: training with the images batch#3\n",
      "INFO: training with the images batch#4\n",
      "INFO: training with the images batch#5\n",
      "INFO: training with the images batch#6\n",
      "INFO: training with the images batch#7\n",
      "INFO: training with the images batch#8\n",
      "INFO: training with the images batch#9\n",
      "INFO: training with the images batch#10\n",
      "INFO: training with the images batch#11\n",
      "INFO: testing time: \t2.1834497451782227\n",
      "INFO: average cross entropy per batch: \t0.9408120413621267\n",
      "INFO: average cluster loss per batch: \t0.774484246969223\n",
      "INFO: separation loss:\t0.7400202850500742\n",
      "INFO: avged separation loss:\t2.5002642273902893\n",
      "INFO: accu: \t50.0%\n",
      "INFO:epoch: \t6\n",
      "INFO: training with the images batch#0\n",
      "INFO: training with the images batch#1\n",
      "INFO: training with the images batch#2\n",
      "INFO: training with the images batch#3\n",
      "INFO: training with the images batch#4\n",
      "INFO: training with the images batch#5\n",
      "INFO: training with the images batch#6\n",
      "INFO: training with the images batch#7\n",
      "INFO: training with the images batch#8\n",
      "INFO: training with the images batch#9\n",
      "INFO: training with the images batch#10\n",
      "INFO: training with the images batch#11\n",
      "INFO: training time: \t7.991426467895508\n",
      "INFO: average cross entropy per batch: \t0.8275367071231207\n",
      "INFO: average cluster loss per batch: \t0.7990877677996954\n",
      "INFO: separation loss:\t0.8006265610456467\n",
      "INFO: avged separation loss:\t2.5641289750734964\n",
      "INFO: accu: \t53.333333333333336%\n",
      "INFO: training with the images batch#0\n",
      "INFO: training with the images batch#1\n",
      "INFO: training with the images batch#2\n",
      "INFO: training with the images batch#3\n",
      "INFO: training with the images batch#4\n",
      "INFO: training with the images batch#5\n",
      "INFO: training with the images batch#6\n",
      "INFO: training with the images batch#7\n",
      "INFO: training with the images batch#8\n",
      "INFO: training with the images batch#9\n",
      "INFO: training with the images batch#10\n",
      "INFO: training with the images batch#11\n",
      "INFO: testing time: \t2.1596484184265137\n",
      "INFO: average cross entropy per batch: \t0.7522524471084276\n",
      "INFO: average cluster loss per batch: \t0.7913388858238856\n",
      "INFO: separation loss:\t0.7694600025812784\n",
      "INFO: avged separation loss:\t2.587258597215017\n",
      "INFO: accu: \t50.0%\n",
      "INFO:epoch: \t7\n",
      "INFO: training with the images batch#0\n",
      "INFO: training with the images batch#1\n",
      "INFO: training with the images batch#2\n",
      "INFO: training with the images batch#3\n",
      "INFO: training with the images batch#4\n",
      "INFO: training with the images batch#5\n",
      "INFO: training with the images batch#6\n",
      "INFO: training with the images batch#7\n",
      "INFO: training with the images batch#8\n",
      "INFO: training with the images batch#9\n",
      "INFO: training with the images batch#10\n",
      "INFO: training with the images batch#11\n",
      "INFO: training time: \t7.848824739456177\n",
      "INFO: average cross entropy per batch: \t0.8105924452344576\n",
      "INFO: average cluster loss per batch: \t0.758871411283811\n",
      "INFO: separation loss:\t0.7556773473819097\n",
      "INFO: avged separation loss:\t2.5662007331848145\n",
      "INFO: accu: \t45.0%\n",
      "INFO: training with the images batch#0\n",
      "INFO: training with the images batch#1\n",
      "INFO: training with the images batch#2\n",
      "INFO: training with the images batch#3\n",
      "INFO: training with the images batch#4\n",
      "INFO: training with the images batch#5\n",
      "INFO: training with the images batch#6\n",
      "INFO: training with the images batch#7\n",
      "INFO: training with the images batch#8\n",
      "INFO: training with the images batch#9\n",
      "INFO: training with the images batch#10\n",
      "INFO: training with the images batch#11\n",
      "INFO: testing time: \t1.888535976409912\n",
      "INFO: average cross entropy per batch: \t0.7031572163105011\n",
      "INFO: average cluster loss per batch: \t0.7602674315373102\n",
      "INFO: separation loss:\t0.7576080858707428\n",
      "INFO: avged separation loss:\t2.6501707633336387\n",
      "INFO: accu: \t55.00000000000001%\n",
      "INFO:epoch: \t8\n",
      "INFO: training with the images batch#0\n",
      "INFO: training with the images batch#1\n",
      "INFO: training with the images batch#2\n",
      "INFO: training with the images batch#3\n",
      "INFO: training with the images batch#4\n",
      "INFO: training with the images batch#5\n",
      "INFO: training with the images batch#6\n",
      "INFO: training with the images batch#7\n",
      "INFO: training with the images batch#8\n",
      "INFO: training with the images batch#9\n",
      "INFO: training with the images batch#10\n",
      "INFO: training with the images batch#11\n",
      "INFO: training time: \t7.732670307159424\n",
      "INFO: average cross entropy per batch: \t0.7063314020633698\n",
      "INFO: average cluster loss per batch: \t0.7108797679344813\n",
      "INFO: separation loss:\t0.760223776102066\n",
      "INFO: avged separation loss:\t2.61522767941157\n",
      "INFO: accu: \t51.66666666666667%\n",
      "INFO: training with the images batch#0\n",
      "INFO: training with the images batch#1\n",
      "INFO: training with the images batch#2\n",
      "INFO: training with the images batch#3\n",
      "INFO: training with the images batch#4\n",
      "INFO: training with the images batch#5\n",
      "INFO: training with the images batch#6\n",
      "INFO: training with the images batch#7\n",
      "INFO: training with the images batch#8\n",
      "INFO: training with the images batch#9\n",
      "INFO: training with the images batch#10\n",
      "INFO: training with the images batch#11\n",
      "INFO: testing time: \t2.2715978622436523\n",
      "INFO: average cross entropy per batch: \t0.707976388434569\n",
      "INFO: average cluster loss per batch: \t0.680856466293335\n",
      "INFO: separation loss:\t0.6944525490204493\n",
      "INFO: avged separation loss:\t2.5312837759653726\n",
      "INFO: accu: \t51.66666666666667%\n",
      "INFO:epoch: \t9\n",
      "INFO: training with the images batch#0\n",
      "INFO: training with the images batch#1\n",
      "INFO: training with the images batch#2\n",
      "INFO: training with the images batch#3\n",
      "INFO: training with the images batch#4\n",
      "INFO: training with the images batch#5\n",
      "INFO: training with the images batch#6\n",
      "INFO: training with the images batch#7\n",
      "INFO: training with the images batch#8\n",
      "INFO: training with the images batch#9\n",
      "INFO: training with the images batch#10\n",
      "INFO: training with the images batch#11\n",
      "INFO: training time: \t7.958759069442749\n",
      "INFO: average cross entropy per batch: \t0.6645146558682123\n",
      "INFO: average cluster loss per batch: \t0.6250175585349401\n",
      "INFO: separation loss:\t0.6724591851234436\n",
      "INFO: avged separation loss:\t2.513315657774607\n",
      "INFO: accu: \t66.66666666666666%\n",
      "INFO: training with the images batch#0\n",
      "INFO: training with the images batch#1\n",
      "INFO: training with the images batch#2\n",
      "INFO: training with the images batch#3\n",
      "INFO: training with the images batch#4\n",
      "INFO: training with the images batch#5\n",
      "INFO: training with the images batch#6\n",
      "INFO: training with the images batch#7\n",
      "INFO: training with the images batch#8\n",
      "INFO: training with the images batch#9\n",
      "INFO: training with the images batch#10\n",
      "INFO: training with the images batch#11\n",
      "INFO: testing time: \t2.7112390995025635\n",
      "INFO: average cross entropy per batch: \t0.68219393491745\n",
      "INFO: average cluster loss per batch: \t0.6004179914792379\n",
      "INFO: separation loss:\t0.613468180100123\n",
      "INFO: avged separation loss:\t2.500389317671458\n",
      "INFO: accu: \t60.0%\n",
      "INFO:epoch: \t10\n",
      "INFO: training with the images batch#0\n",
      "INFO: training with the images batch#1\n",
      "INFO: training with the images batch#2\n",
      "INFO: training with the images batch#3\n",
      "INFO: training with the images batch#4\n",
      "INFO: training with the images batch#5\n",
      "INFO: training with the images batch#6\n",
      "INFO: training with the images batch#7\n",
      "INFO: training with the images batch#8\n",
      "INFO: training with the images batch#9\n",
      "INFO: training with the images batch#10\n",
      "INFO: training with the images batch#11\n",
      "INFO: training time: \t7.612960338592529\n",
      "INFO: average cross entropy per batch: \t0.6485481560230255\n",
      "INFO: average cluster loss per batch: \t0.6159051259358724\n",
      "INFO: separation loss:\t0.6563783238331476\n",
      "INFO: avged separation loss:\t2.560728887716929\n",
      "INFO: accu: \t73.33333333333333%\n",
      "INFO: training with the images batch#0\n",
      "INFO: training with the images batch#1\n",
      "INFO: training with the images batch#2\n",
      "INFO: training with the images batch#3\n",
      "INFO: training with the images batch#4\n",
      "INFO: training with the images batch#5\n",
      "INFO: training with the images batch#6\n",
      "INFO: training with the images batch#7\n",
      "INFO: training with the images batch#8\n",
      "INFO: training with the images batch#9\n",
      "INFO: training with the images batch#10\n",
      "INFO: training with the images batch#11\n",
      "INFO: testing time: \t2.453291416168213\n",
      "INFO: average cross entropy per batch: \t0.6754566580057144\n",
      "INFO: average cluster loss per batch: \t0.6194721013307571\n",
      "INFO: separation loss:\t0.6364022791385651\n",
      "INFO: avged separation loss:\t2.555403788884481\n",
      "INFO: accu: \t63.33333333333333%\n",
      "INFO: training with the images batch#0\n",
      "INFO: training with the images batch#1\n",
      "INFO: training with the images batch#2\n",
      "INFO: training with the images batch#3\n",
      "INFO: training with the images batch#4\n",
      "INFO: training with the images batch#5\n",
      "INFO: training with the images batch#6\n",
      "INFO: training with the images batch#7\n",
      "INFO: training with the images batch#8\n",
      "INFO: training with the images batch#9\n",
      "INFO: training with the images batch#10\n",
      "INFO: training with the images batch#11\n",
      "INFO: testing time: \t1.8859102725982666\n",
      "INFO: average cross entropy per batch: \t17.56668878518879\n",
      "INFO: average cluster loss per batch: \t0.0007620414035045542\n",
      "INFO: separation loss:\t0.0006374120791103147\n",
      "INFO: avged separation loss:\t0.1538341330985228\n",
      "INFO: accu: \t46.666666666666664%\n",
      "INFO: training with the images batch#0\n",
      "INFO: training with the images batch#1\n",
      "INFO: training with the images batch#2\n",
      "INFO: training with the images batch#3\n",
      "INFO: training with the images batch#4\n",
      "INFO: training with the images batch#5\n",
      "INFO: training with the images batch#6\n",
      "INFO: training with the images batch#7\n",
      "INFO: training with the images batch#8\n",
      "INFO: training with the images batch#9\n",
      "INFO: training with the images batch#10\n",
      "INFO: training with the images batch#11\n",
      "INFO: training time: \t2.408930778503418\n",
      "INFO: average cross entropy per batch: \t11.309961905082067\n",
      "INFO: average cluster loss per batch: \t0.0005374670034446657\n",
      "INFO: separation loss:\t0.0012783527411860025\n",
      "INFO: avged separation loss:\t0.16437147868176302\n",
      "INFO: accu: \t60.0%\n",
      "INFO: training with the images batch#0\n",
      "INFO: training with the images batch#1\n",
      "INFO: training with the images batch#2\n",
      "INFO: training with the images batch#3\n",
      "INFO: training with the images batch#4\n",
      "INFO: training with the images batch#5\n",
      "INFO: training with the images batch#6\n",
      "INFO: training with the images batch#7\n",
      "INFO: training with the images batch#8\n",
      "INFO: training with the images batch#9\n",
      "INFO: training with the images batch#10\n",
      "INFO: training with the images batch#11\n",
      "INFO: testing time: \t2.2628748416900635\n",
      "INFO: average cross entropy per batch: \t17.269556901611697\n",
      "INFO: average cluster loss per batch: \t0.0007620414035045542\n",
      "INFO: separation loss:\t0.0006374120791103147\n",
      "INFO: avged separation loss:\t0.1538341330985228\n",
      "INFO: accu: \t46.666666666666664%\n",
      "INFO: training with the images batch#0\n",
      "INFO: training with the images batch#1\n",
      "INFO: training with the images batch#2\n",
      "INFO: training with the images batch#3\n",
      "INFO: training with the images batch#4\n",
      "INFO: training with the images batch#5\n",
      "INFO: training with the images batch#6\n",
      "INFO: training with the images batch#7\n",
      "INFO: training with the images batch#8\n",
      "INFO: training with the images batch#9\n",
      "INFO: training with the images batch#10\n",
      "INFO: training with the images batch#11\n",
      "INFO: training time: \t2.0957422256469727\n",
      "INFO: average cross entropy per batch: \t10.914440577323452\n",
      "INFO: average cluster loss per batch: \t0.0005374670105690408\n",
      "INFO: separation loss:\t0.0012783527054125443\n",
      "INFO: avged separation loss:\t0.16437148240705332\n",
      "INFO: accu: \t60.0%\n",
      "INFO: training with the images batch#0\n",
      "INFO: training with the images batch#1\n",
      "INFO: training with the images batch#2\n",
      "INFO: training with the images batch#3\n",
      "INFO: training with the images batch#4\n",
      "INFO: training with the images batch#5\n",
      "INFO: training with the images batch#6\n",
      "INFO: training with the images batch#7\n",
      "INFO: training with the images batch#8\n",
      "INFO: training with the images batch#9\n",
      "INFO: training with the images batch#10\n",
      "INFO: training with the images batch#11\n",
      "INFO: testing time: \t2.4344773292541504\n",
      "INFO: average cross entropy per batch: \t16.993319008606097\n",
      "INFO: average cluster loss per batch: \t0.0007620414035045542\n",
      "INFO: separation loss:\t0.0006374120791103147\n",
      "INFO: avged separation loss:\t0.1538341330985228\n",
      "INFO: accu: \t46.666666666666664%\n",
      "INFO: training with the images batch#0\n",
      "INFO: training with the images batch#1\n",
      "INFO: training with the images batch#2\n",
      "INFO: training with the images batch#3\n",
      "INFO: training with the images batch#4\n",
      "INFO: training with the images batch#5\n",
      "INFO: training with the images batch#6\n",
      "INFO: training with the images batch#7\n",
      "INFO: training with the images batch#8\n",
      "INFO: training with the images batch#9\n",
      "INFO: training with the images batch#10\n",
      "INFO: training with the images batch#11\n",
      "INFO: training time: \t2.3491742610931396\n",
      "INFO: average cross entropy per batch: \t10.585522562265396\n",
      "INFO: average cluster loss per batch: \t0.0005374669954107958\n",
      "INFO: separation loss:\t0.0012783527463398059\n",
      "INFO: avged separation loss:\t0.16437148054440817\n",
      "INFO: accu: \t60.0%\n",
      "INFO: training with the images batch#0\n",
      "INFO: training with the images batch#1\n",
      "INFO: training with the images batch#2\n",
      "INFO: training with the images batch#3\n",
      "INFO: training with the images batch#4\n",
      "INFO: training with the images batch#5\n",
      "INFO: training with the images batch#6\n",
      "INFO: training with the images batch#7\n",
      "INFO: training with the images batch#8\n",
      "INFO: training with the images batch#9\n",
      "INFO: training with the images batch#10\n",
      "INFO: training with the images batch#11\n",
      "INFO: testing time: \t2.179422616958618\n",
      "INFO: average cross entropy per batch: \t16.70886919401043\n",
      "INFO: average cluster loss per batch: \t0.0007620414035045542\n",
      "INFO: separation loss:\t0.0006374120791103147\n",
      "INFO: avged separation loss:\t0.1538341330985228\n",
      "INFO: accu: \t46.666666666666664%\n",
      "INFO: training with the images batch#0\n",
      "INFO: training with the images batch#1\n",
      "INFO: training with the images batch#2\n",
      "INFO: training with the images batch#3\n",
      "INFO: training with the images batch#4\n",
      "INFO: training with the images batch#5\n",
      "INFO: training with the images batch#6\n",
      "INFO: training with the images batch#7\n",
      "INFO: training with the images batch#8\n",
      "INFO: training with the images batch#9\n",
      "INFO: training with the images batch#10\n",
      "INFO: training with the images batch#11\n",
      "INFO: training time: \t2.4699301719665527\n",
      "INFO: average cross entropy per batch: \t10.207370897134146\n",
      "INFO: average cluster loss per batch: \t0.0005374670064763146\n",
      "INFO: separation loss:\t0.0012783527169328106\n",
      "INFO: avged separation loss:\t0.16437147743999958\n",
      "INFO: accu: \t60.0%\n",
      "INFO: training with the images batch#0\n",
      "INFO: training with the images batch#1\n",
      "INFO: training with the images batch#2\n",
      "INFO: training with the images batch#3\n",
      "INFO: training with the images batch#4\n",
      "INFO: training with the images batch#5\n",
      "INFO: training with the images batch#6\n",
      "INFO: training with the images batch#7\n",
      "INFO: training with the images batch#8\n",
      "INFO: training with the images batch#9\n",
      "INFO: training with the images batch#10\n",
      "INFO: training with the images batch#11\n",
      "INFO: testing time: \t2.1488378047943115\n",
      "INFO: average cross entropy per batch: \t16.44217516373222\n",
      "INFO: average cluster loss per batch: \t0.0007620414035045542\n",
      "INFO: separation loss:\t0.0006374120791103147\n",
      "INFO: avged separation loss:\t0.1538341330985228\n",
      "INFO: accu: \t46.666666666666664%\n",
      "INFO: training with the images batch#0\n",
      "INFO: training with the images batch#1\n",
      "INFO: training with the images batch#2\n",
      "INFO: training with the images batch#3\n",
      "INFO: training with the images batch#4\n",
      "INFO: training with the images batch#5\n",
      "INFO: training with the images batch#6\n",
      "INFO: training with the images batch#7\n",
      "INFO: training with the images batch#8\n",
      "INFO: training with the images batch#9\n",
      "INFO: training with the images batch#10\n",
      "INFO: training with the images batch#11\n",
      "INFO: training time: \t2.158432960510254\n",
      "INFO: average cross entropy per batch: \t9.864010021090508\n",
      "INFO: average cluster loss per batch: \t0.0005374670057184024\n",
      "INFO: separation loss:\t0.0012783527508872794\n",
      "INFO: avged separation loss:\t0.16437147619823614\n",
      "INFO: accu: \t60.0%\n",
      "INFO: training with the images batch#0\n",
      "INFO: training with the images batch#1\n",
      "INFO: training with the images batch#2\n",
      "INFO: training with the images batch#3\n",
      "INFO: training with the images batch#4\n",
      "INFO: training with the images batch#5\n",
      "INFO: training with the images batch#6\n",
      "INFO: training with the images batch#7\n",
      "INFO: training with the images batch#8\n",
      "INFO: training with the images batch#9\n",
      "INFO: training with the images batch#10\n",
      "INFO: training with the images batch#11\n",
      "INFO: testing time: \t2.1932027339935303\n",
      "INFO: average cross entropy per batch: \t16.16858770841888\n",
      "INFO: average cluster loss per batch: \t0.0007620414035045542\n",
      "INFO: separation loss:\t0.0006374120791103147\n",
      "INFO: avged separation loss:\t0.1538341330985228\n",
      "INFO: accu: \t46.666666666666664%\n",
      "INFO: training with the images batch#0\n",
      "INFO: training with the images batch#1\n",
      "INFO: training with the images batch#2\n",
      "INFO: training with the images batch#3\n",
      "INFO: training with the images batch#4\n",
      "INFO: training with the images batch#5\n",
      "INFO: training with the images batch#6\n",
      "INFO: training with the images batch#7\n",
      "INFO: training with the images batch#8\n",
      "INFO: training with the images batch#9\n",
      "INFO: training with the images batch#10\n",
      "INFO: training with the images batch#11\n",
      "INFO: training time: \t2.4542713165283203\n",
      "INFO: average cross entropy per batch: \t9.507407367229462\n",
      "INFO: average cluster loss per batch: \t0.000537466989423289\n",
      "INFO: separation loss:\t0.0012783527193581297\n",
      "INFO: avged separation loss:\t0.16437147681911787\n",
      "INFO: accu: \t60.0%\n",
      "INFO: training with the images batch#0\n",
      "INFO: training with the images batch#1\n",
      "INFO: training with the images batch#2\n",
      "INFO: training with the images batch#3\n",
      "INFO: training with the images batch#4\n",
      "INFO: training with the images batch#5\n",
      "INFO: training with the images batch#6\n",
      "INFO: training with the images batch#7\n",
      "INFO: training with the images batch#8\n",
      "INFO: training with the images batch#9\n",
      "INFO: training with the images batch#10\n",
      "INFO: training with the images batch#11\n",
      "INFO: testing time: \t2.1906285285949707\n",
      "INFO: average cross entropy per batch: \t15.898571749140197\n",
      "INFO: average cluster loss per batch: \t0.0007620414035045542\n",
      "INFO: separation loss:\t0.0006374120791103147\n",
      "INFO: avged separation loss:\t0.1538341330985228\n",
      "INFO: accu: \t46.666666666666664%\n",
      "INFO: training with the images batch#0\n",
      "INFO: training with the images batch#1\n",
      "INFO: training with the images batch#2\n",
      "INFO: training with the images batch#3\n",
      "INFO: training with the images batch#4\n",
      "INFO: training with the images batch#5\n",
      "INFO: training with the images batch#6\n",
      "INFO: training with the images batch#7\n",
      "INFO: training with the images batch#8\n",
      "INFO: training with the images batch#9\n",
      "INFO: training with the images batch#10\n",
      "INFO: training with the images batch#11\n",
      "INFO: training time: \t2.1982908248901367\n",
      "INFO: average cross entropy per batch: \t9.164228528738022\n",
      "INFO: average cluster loss per batch: \t0.0005374669999582693\n",
      "INFO: separation loss:\t0.0012783527375480237\n",
      "INFO: avged separation loss:\t0.16437147899220386\n",
      "INFO: accu: \t60.0%\n",
      "INFO: training with the images batch#0\n",
      "INFO: training with the images batch#1\n",
      "INFO: training with the images batch#2\n",
      "INFO: training with the images batch#3\n",
      "INFO: training with the images batch#4\n",
      "INFO: training with the images batch#5\n",
      "INFO: training with the images batch#6\n",
      "INFO: training with the images batch#7\n",
      "INFO: training with the images batch#8\n",
      "INFO: training with the images batch#9\n",
      "INFO: training with the images batch#10\n",
      "INFO: training with the images batch#11\n",
      "INFO: testing time: \t2.4059252738952637\n",
      "INFO: average cross entropy per batch: \t15.627555769712975\n",
      "INFO: average cluster loss per batch: \t0.0007620414035045542\n",
      "INFO: separation loss:\t0.0006374120791103147\n",
      "INFO: avged separation loss:\t0.1538341330985228\n",
      "INFO: accu: \t46.666666666666664%\n",
      "INFO: training with the images batch#0\n",
      "INFO: training with the images batch#1\n",
      "INFO: training with the images batch#2\n",
      "INFO: training with the images batch#3\n",
      "INFO: training with the images batch#4\n",
      "INFO: training with the images batch#5\n",
      "INFO: training with the images batch#6\n",
      "INFO: training with the images batch#7\n",
      "INFO: training with the images batch#8\n",
      "INFO: training with the images batch#9\n",
      "INFO: training with the images batch#10\n",
      "INFO: training with the images batch#11\n",
      "INFO: training time: \t2.1790196895599365\n",
      "INFO: average cross entropy per batch: \t8.811281288663546\n",
      "INFO: average cluster loss per batch: \t0.0005374670057184024\n",
      "INFO: separation loss:\t0.0012783527232992735\n",
      "INFO: avged separation loss:\t0.16437147930264473\n",
      "INFO: accu: \t60.0%\n",
      "INFO: training with the images batch#0\n",
      "INFO: training with the images batch#1\n",
      "INFO: training with the images batch#2\n",
      "INFO: training with the images batch#3\n",
      "INFO: training with the images batch#4\n",
      "INFO: training with the images batch#5\n",
      "INFO: training with the images batch#6\n",
      "INFO: training with the images batch#7\n",
      "INFO: training with the images batch#8\n",
      "INFO: training with the images batch#9\n",
      "INFO: training with the images batch#10\n",
      "INFO: training with the images batch#11\n",
      "INFO: testing time: \t2.201334238052368\n",
      "INFO: average cross entropy per batch: \t15.366925581979254\n",
      "INFO: average cluster loss per batch: \t0.0007620414035045542\n",
      "INFO: separation loss:\t0.0006374120791103147\n",
      "INFO: avged separation loss:\t0.1538341330985228\n",
      "INFO: accu: \t46.666666666666664%\n",
      "INFO: training with the images batch#0\n",
      "INFO: training with the images batch#1\n",
      "INFO: training with the images batch#2\n",
      "INFO: training with the images batch#3\n",
      "INFO: training with the images batch#4\n",
      "INFO: training with the images batch#5\n",
      "INFO: training with the images batch#6\n",
      "INFO: training with the images batch#7\n",
      "INFO: training with the images batch#8\n",
      "INFO: training with the images batch#9\n",
      "INFO: training with the images batch#10\n",
      "INFO: training with the images batch#11\n",
      "INFO: training time: \t2.453442335128784\n",
      "INFO: average cross entropy per batch: \t8.462991385526644\n",
      "INFO: average cluster loss per batch: \t0.0005374670108722057\n",
      "INFO: separation loss:\t0.0012783527287562417\n",
      "INFO: avged separation loss:\t0.164371474335591\n",
      "INFO: accu: \t60.0%\n",
      "INFO: training with the images batch#0\n",
      "INFO: training with the images batch#1\n",
      "INFO: training with the images batch#2\n",
      "INFO: training with the images batch#3\n",
      "INFO: training with the images batch#4\n",
      "INFO: training with the images batch#5\n",
      "INFO: training with the images batch#6\n",
      "INFO: training with the images batch#7\n",
      "INFO: training with the images batch#8\n",
      "INFO: training with the images batch#9\n",
      "INFO: training with the images batch#10\n",
      "INFO: training with the images batch#11\n",
      "INFO: testing time: \t2.184455633163452\n",
      "INFO: average cross entropy per batch: \t15.123628210276365\n",
      "INFO: average cluster loss per batch: \t0.0007620414035045542\n",
      "INFO: separation loss:\t0.0006374120791103147\n",
      "INFO: avged separation loss:\t0.1538341330985228\n",
      "INFO: accu: \t46.666666666666664%\n",
      "INFO: training with the images batch#0\n",
      "INFO: training with the images batch#1\n",
      "INFO: training with the images batch#2\n",
      "INFO: training with the images batch#3\n",
      "INFO: training with the images batch#4\n",
      "INFO: training with the images batch#5\n",
      "INFO: training with the images batch#6\n",
      "INFO: training with the images batch#7\n",
      "INFO: training with the images batch#8\n",
      "INFO: training with the images batch#9\n",
      "INFO: training with the images batch#10\n",
      "INFO: training with the images batch#11\n",
      "INFO: training time: \t2.171905040740967\n",
      "INFO: average cross entropy per batch: \t8.156007712086042\n",
      "INFO: average cluster loss per batch: \t0.0005374670020804236\n",
      "INFO: separation loss:\t0.0012783527199644595\n",
      "INFO: avged separation loss:\t0.16437147868176302\n",
      "INFO: accu: \t60.0%\n",
      "INFO: training with the images batch#0\n",
      "INFO: training with the images batch#1\n",
      "INFO: training with the images batch#2\n",
      "INFO: training with the images batch#3\n",
      "INFO: training with the images batch#4\n",
      "INFO: training with the images batch#5\n",
      "INFO: training with the images batch#6\n",
      "INFO: training with the images batch#7\n",
      "INFO: training with the images batch#8\n",
      "INFO: training with the images batch#9\n",
      "INFO: training with the images batch#10\n",
      "INFO: training with the images batch#11\n",
      "INFO: testing time: \t2.4517011642456055\n",
      "INFO: average cross entropy per batch: \t14.877548715720573\n",
      "INFO: average cluster loss per batch: \t0.0007620414035045542\n",
      "INFO: separation loss:\t0.0006374120791103147\n",
      "INFO: avged separation loss:\t0.1538341330985228\n",
      "INFO: accu: \t48.333333333333336%\n",
      "INFO: training with the images batch#0\n",
      "INFO: training with the images batch#1\n",
      "INFO: training with the images batch#2\n",
      "INFO: training with the images batch#3\n",
      "INFO: training with the images batch#4\n",
      "INFO: training with the images batch#5\n",
      "INFO: training with the images batch#6\n",
      "INFO: training with the images batch#7\n",
      "INFO: training with the images batch#8\n",
      "INFO: training with the images batch#9\n",
      "INFO: training with the images batch#10\n",
      "INFO: training with the images batch#11\n",
      "INFO: training time: \t1.9215221405029297\n",
      "INFO: average cross entropy per batch: \t7.835657996901621\n",
      "INFO: average cluster loss per batch: \t0.0005374670145101845\n",
      "INFO: separation loss:\t0.0012783527151138212\n",
      "INFO: avged separation loss:\t0.16437147743999958\n",
      "INFO: accu: \t63.33333333333333%\n",
      "INFO: training with the images batch#0\n",
      "INFO: training with the images batch#1\n",
      "INFO: training with the images batch#2\n",
      "INFO: training with the images batch#3\n",
      "INFO: training with the images batch#4\n",
      "INFO: training with the images batch#5\n",
      "INFO: training with the images batch#6\n",
      "INFO: training with the images batch#7\n",
      "INFO: training with the images batch#8\n",
      "INFO: training with the images batch#9\n",
      "INFO: training with the images batch#10\n",
      "INFO: training with the images batch#11\n",
      "INFO: testing time: \t2.416450262069702\n",
      "INFO: average cross entropy per batch: \t14.664749530454477\n",
      "INFO: average cluster loss per batch: \t0.0007620414035045542\n",
      "INFO: separation loss:\t0.0006374120791103147\n",
      "INFO: avged separation loss:\t0.1538341330985228\n",
      "INFO: accu: \t46.666666666666664%\n",
      "INFO: training with the images batch#0\n",
      "INFO: training with the images batch#1\n",
      "INFO: training with the images batch#2\n",
      "INFO: training with the images batch#3\n",
      "INFO: training with the images batch#4\n",
      "INFO: training with the images batch#5\n",
      "INFO: training with the images batch#6\n",
      "INFO: training with the images batch#7\n",
      "INFO: training with the images batch#8\n",
      "INFO: training with the images batch#9\n",
      "INFO: training with the images batch#10\n",
      "INFO: training with the images batch#11\n",
      "INFO: training time: \t2.4783475399017334\n",
      "INFO: average cross entropy per batch: \t7.535302745799224\n",
      "INFO: average cluster loss per batch: \t0.0005374669872253435\n",
      "INFO: separation loss:\t0.0012783527320910555\n",
      "INFO: avged separation loss:\t0.16437147681911787\n",
      "INFO: accu: \t63.33333333333333%\n",
      "INFO: training with the images batch#0\n",
      "INFO: training with the images batch#1\n",
      "INFO: training with the images batch#2\n",
      "INFO: training with the images batch#3\n",
      "INFO: training with the images batch#4\n",
      "INFO: training with the images batch#5\n",
      "INFO: training with the images batch#6\n",
      "INFO: training with the images batch#7\n",
      "INFO: training with the images batch#8\n",
      "INFO: training with the images batch#9\n",
      "INFO: training with the images batch#10\n",
      "INFO: training with the images batch#11\n",
      "INFO: testing time: \t1.926114797592163\n",
      "INFO: average cross entropy per batch: \t14.48201003919045\n",
      "INFO: average cluster loss per batch: \t0.0007620414035045542\n",
      "INFO: separation loss:\t0.0006374120791103147\n",
      "INFO: avged separation loss:\t0.1538341330985228\n",
      "INFO: accu: \t41.66666666666667%\n",
      "INFO: training with the images batch#0\n",
      "INFO: training with the images batch#1\n",
      "INFO: training with the images batch#2\n",
      "INFO: training with the images batch#3\n",
      "INFO: training with the images batch#4\n",
      "INFO: training with the images batch#5\n",
      "INFO: training with the images batch#6\n",
      "INFO: training with the images batch#7\n",
      "INFO: training with the images batch#8\n",
      "INFO: training with the images batch#9\n",
      "INFO: training with the images batch#10\n",
      "INFO: training with the images batch#11\n",
      "INFO: training time: \t2.4682233333587646\n",
      "INFO: average cross entropy per batch: \t7.26927162706852\n",
      "INFO: average cluster loss per batch: \t0.0005374670087500514\n",
      "INFO: separation loss:\t0.0012783527114758424\n",
      "INFO: avged separation loss:\t0.1643714780608813\n",
      "INFO: accu: \t61.66666666666667%\n",
      "INFO: training with the images batch#0\n",
      "INFO: training with the images batch#1\n",
      "INFO: training with the images batch#2\n",
      "INFO: training with the images batch#3\n",
      "INFO: training with the images batch#4\n",
      "INFO: training with the images batch#5\n",
      "INFO: training with the images batch#6\n",
      "INFO: training with the images batch#7\n",
      "INFO: training with the images batch#8\n",
      "INFO: training with the images batch#9\n",
      "INFO: training with the images batch#10\n",
      "INFO: training with the images batch#11\n",
      "INFO: testing time: \t2.4472503662109375\n",
      "INFO: average cross entropy per batch: \t14.321356050670147\n",
      "INFO: average cluster loss per batch: \t0.0007620414035045542\n",
      "INFO: separation loss:\t0.0006374120791103147\n",
      "INFO: avged separation loss:\t0.1538341330985228\n",
      "INFO: accu: \t41.66666666666667%\n",
      "INFO: training with the images batch#0\n",
      "INFO: training with the images batch#1\n",
      "INFO: training with the images batch#2\n",
      "INFO: training with the images batch#3\n",
      "INFO: training with the images batch#4\n",
      "INFO: training with the images batch#5\n",
      "INFO: training with the images batch#6\n",
      "INFO: training with the images batch#7\n",
      "INFO: training with the images batch#8\n",
      "INFO: training with the images batch#9\n",
      "INFO: training with the images batch#10\n",
      "INFO: training with the images batch#11\n",
      "INFO: training time: \t1.8808157444000244\n",
      "INFO: average cross entropy per batch: \t7.027022262414296\n",
      "INFO: average cluster loss per batch: \t0.000537467016026009\n",
      "INFO: separation loss:\t0.00127835274906829\n",
      "INFO: avged separation loss:\t0.16437147743999958\n",
      "INFO: accu: \t61.66666666666667%\n",
      "INFO: training with the images batch#0\n",
      "INFO: training with the images batch#1\n",
      "INFO: training with the images batch#2\n",
      "INFO: training with the images batch#3\n",
      "INFO: training with the images batch#4\n",
      "INFO: training with the images batch#5\n",
      "INFO: training with the images batch#6\n",
      "INFO: training with the images batch#7\n",
      "INFO: training with the images batch#8\n",
      "INFO: training with the images batch#9\n",
      "INFO: training with the images batch#10\n",
      "INFO: training with the images batch#11\n",
      "INFO: testing time: \t2.4807322025299072\n",
      "INFO: average cross entropy per batch: \t14.185651108622551\n",
      "INFO: average cluster loss per batch: \t0.0007620414035045542\n",
      "INFO: separation loss:\t0.0006374120791103147\n",
      "INFO: avged separation loss:\t0.1538341330985228\n",
      "INFO: accu: \t43.333333333333336%\n",
      "INFO: training with the images batch#0\n",
      "INFO: training with the images batch#1\n",
      "INFO: training with the images batch#2\n",
      "INFO: training with the images batch#3\n",
      "INFO: training with the images batch#4\n",
      "INFO: training with the images batch#5\n",
      "INFO: training with the images batch#6\n",
      "INFO: training with the images batch#7\n",
      "INFO: training with the images batch#8\n",
      "INFO: training with the images batch#9\n",
      "INFO: training with the images batch#10\n",
      "INFO: training with the images batch#11\n",
      "INFO: training time: \t2.4421470165252686\n",
      "INFO: average cross entropy per batch: \t6.815324552357197\n",
      "INFO: average cluster loss per batch: \t0.000537467010265876\n",
      "INFO: separation loss:\t0.0012783527311815608\n",
      "INFO: avged separation loss:\t0.16437148302793503\n",
      "INFO: accu: \t61.66666666666667%\n",
      "INFO: training with the images batch#0\n",
      "INFO: training with the images batch#1\n",
      "INFO: training with the images batch#2\n",
      "INFO: training with the images batch#3\n",
      "INFO: training with the images batch#4\n",
      "INFO: training with the images batch#5\n",
      "INFO: training with the images batch#6\n",
      "INFO: training with the images batch#7\n",
      "INFO: training with the images batch#8\n",
      "INFO: training with the images batch#9\n",
      "INFO: training with the images batch#10\n",
      "INFO: training with the images batch#11\n",
      "INFO: testing time: \t1.880152702331543\n",
      "INFO: average cross entropy per batch: \t14.070078055063883\n",
      "INFO: average cluster loss per batch: \t0.0007620414035045542\n",
      "INFO: separation loss:\t0.0006374120791103147\n",
      "INFO: avged separation loss:\t0.1538341330985228\n",
      "INFO: accu: \t41.66666666666667%\n",
      "INFO: training with the images batch#0\n",
      "INFO: training with the images batch#1\n",
      "INFO: training with the images batch#2\n",
      "INFO: training with the images batch#3\n",
      "INFO: training with the images batch#4\n",
      "INFO: training with the images batch#5\n",
      "INFO: training with the images batch#6\n",
      "INFO: training with the images batch#7\n",
      "INFO: training with the images batch#8\n",
      "INFO: training with the images batch#9\n",
      "INFO: training with the images batch#10\n",
      "INFO: training with the images batch#11\n",
      "INFO: training time: \t2.477057456970215\n",
      "INFO: average cross entropy per batch: \t6.631592546900113\n",
      "INFO: average cluster loss per batch: \t0.0005374669941981362\n",
      "INFO: separation loss:\t0.0012783527314847258\n",
      "INFO: avged separation loss:\t0.16437147681911787\n",
      "INFO: accu: \t61.66666666666667%\n",
      "INFO: training with the images batch#0\n",
      "INFO: training with the images batch#1\n",
      "INFO: training with the images batch#2\n",
      "INFO: training with the images batch#3\n",
      "INFO: training with the images batch#4\n",
      "INFO: training with the images batch#5\n",
      "INFO: training with the images batch#6\n",
      "INFO: training with the images batch#7\n",
      "INFO: training with the images batch#8\n",
      "INFO: training with the images batch#9\n",
      "INFO: training with the images batch#10\n",
      "INFO: training with the images batch#11\n",
      "INFO: testing time: \t2.4013655185699463\n",
      "INFO: average cross entropy per batch: \t13.971320321162542\n",
      "INFO: average cluster loss per batch: \t0.0007620414035045542\n",
      "INFO: separation loss:\t0.0006374120791103147\n",
      "INFO: avged separation loss:\t0.1538341330985228\n",
      "INFO: accu: \t41.66666666666667%\n",
      "INFO: training with the images batch#0\n",
      "INFO: training with the images batch#1\n",
      "INFO: training with the images batch#2\n",
      "INFO: training with the images batch#3\n",
      "INFO: training with the images batch#4\n",
      "INFO: training with the images batch#5\n",
      "INFO: training with the images batch#6\n",
      "INFO: training with the images batch#7\n",
      "INFO: training with the images batch#8\n",
      "INFO: training with the images batch#9\n",
      "INFO: training with the images batch#10\n",
      "INFO: training with the images batch#11\n",
      "INFO: training time: \t1.9816079139709473\n",
      "INFO: average cross entropy per batch: \t6.512612849473953\n",
      "INFO: average cluster loss per batch: \t0.0005374669902569925\n",
      "INFO: separation loss:\t0.0012783527557379177\n",
      "INFO: avged separation loss:\t0.16437148178617159\n",
      "INFO: accu: \t63.33333333333333%\n",
      "INFO: training with the images batch#0\n",
      "INFO: training with the images batch#1\n",
      "INFO: training with the images batch#2\n",
      "INFO: training with the images batch#3\n",
      "INFO: training with the images batch#4\n",
      "INFO: training with the images batch#5\n",
      "INFO: training with the images batch#6\n",
      "INFO: training with the images batch#7\n",
      "INFO: training with the images batch#8\n",
      "INFO: training with the images batch#9\n",
      "INFO: training with the images batch#10\n",
      "INFO: training with the images batch#11\n",
      "INFO: testing time: \t2.433851718902588\n",
      "INFO: average cross entropy per batch: \t13.873374789953232\n",
      "INFO: average cluster loss per batch: \t0.0007620414035045542\n",
      "INFO: separation loss:\t0.0006374120791103147\n",
      "INFO: avged separation loss:\t0.1538341330985228\n",
      "INFO: accu: \t41.66666666666667%\n",
      "INFO: training with the images batch#0\n",
      "INFO: training with the images batch#1\n",
      "INFO: training with the images batch#2\n",
      "INFO: training with the images batch#3\n",
      "INFO: training with the images batch#4\n",
      "INFO: training with the images batch#5\n",
      "INFO: training with the images batch#6\n",
      "INFO: training with the images batch#7\n",
      "INFO: training with the images batch#8\n",
      "INFO: training with the images batch#9\n",
      "INFO: training with the images batch#10\n",
      "INFO: training with the images batch#11\n",
      "INFO: training time: \t1.887852430343628\n",
      "INFO: average cross entropy per batch: \t6.326723086337249\n",
      "INFO: average cluster loss per batch: \t0.0005374669929854766\n",
      "INFO: separation loss:\t0.001278352755131588\n",
      "INFO: avged separation loss:\t0.16437147619823614\n",
      "INFO: accu: \t63.33333333333333%\n",
      "INFO: training with the images batch#0\n",
      "INFO: training with the images batch#1\n",
      "INFO: training with the images batch#2\n",
      "INFO: training with the images batch#3\n",
      "INFO: training with the images batch#4\n",
      "INFO: training with the images batch#5\n",
      "INFO: training with the images batch#6\n",
      "INFO: training with the images batch#7\n",
      "INFO: training with the images batch#8\n",
      "INFO: training with the images batch#9\n",
      "INFO: training with the images batch#10\n",
      "INFO: training with the images batch#11\n",
      "INFO: testing time: \t2.4108548164367676\n",
      "INFO: average cross entropy per batch: \t13.809973766406378\n",
      "INFO: average cluster loss per batch: \t0.0007620414035045542\n",
      "INFO: separation loss:\t0.0006374120791103147\n",
      "INFO: avged separation loss:\t0.1538341330985228\n",
      "INFO: accu: \t40.0%\n",
      "INFO: training with the images batch#0\n",
      "INFO: training with the images batch#1\n",
      "INFO: training with the images batch#2\n",
      "INFO: training with the images batch#3\n",
      "INFO: training with the images batch#4\n",
      "INFO: training with the images batch#5\n",
      "INFO: training with the images batch#6\n",
      "INFO: training with the images batch#7\n",
      "INFO: training with the images batch#8\n",
      "INFO: training with the images batch#9\n",
      "INFO: training with the images batch#10\n",
      "INFO: training with the images batch#11\n",
      "INFO: training time: \t2.4936585426330566\n",
      "INFO: average cross entropy per batch: \t6.2058878019452095\n",
      "INFO: average cluster loss per batch: \t0.000537466985027398\n",
      "INFO: separation loss:\t0.0012783527508872794\n",
      "INFO: avged separation loss:\t0.16437147619823614\n",
      "INFO: accu: \t63.33333333333333%\n",
      "INFO: training with the images batch#0\n",
      "INFO: training with the images batch#1\n",
      "INFO: training with the images batch#2\n",
      "INFO: training with the images batch#3\n",
      "INFO: training with the images batch#4\n",
      "INFO: training with the images batch#5\n",
      "INFO: training with the images batch#6\n",
      "INFO: training with the images batch#7\n",
      "INFO: training with the images batch#8\n",
      "INFO: training with the images batch#9\n",
      "INFO: training with the images batch#10\n",
      "INFO: training with the images batch#11\n",
      "INFO: testing time: \t1.9393131732940674\n",
      "INFO: average cross entropy per batch: \t13.747090746959051\n",
      "INFO: average cluster loss per batch: \t0.0007620414035045542\n",
      "INFO: separation loss:\t0.0006374120791103147\n",
      "INFO: avged separation loss:\t0.1538341330985228\n",
      "INFO: accu: \t40.0%\n",
      "INFO: training with the images batch#0\n",
      "INFO: training with the images batch#1\n",
      "INFO: training with the images batch#2\n",
      "INFO: training with the images batch#3\n",
      "INFO: training with the images batch#4\n",
      "INFO: training with the images batch#5\n",
      "INFO: training with the images batch#6\n",
      "INFO: training with the images batch#7\n",
      "INFO: training with the images batch#8\n",
      "INFO: training with the images batch#9\n",
      "INFO: training with the images batch#10\n",
      "INFO: training with the images batch#11\n",
      "INFO: training time: \t2.967465877532959\n",
      "INFO: average cross entropy per batch: \t6.094406945010026\n",
      "INFO: average cluster loss per batch: \t0.0005374670163291739\n",
      "INFO: separation loss:\t0.0012783527508872794\n",
      "INFO: avged separation loss:\t0.16437147371470928\n",
      "INFO: accu: \t61.66666666666667%\n",
      "INFO: training with the images batch#0\n",
      "INFO: training with the images batch#1\n",
      "INFO: training with the images batch#2\n",
      "INFO: training with the images batch#3\n",
      "INFO: training with the images batch#4\n",
      "INFO: training with the images batch#5\n",
      "INFO: training with the images batch#6\n",
      "INFO: training with the images batch#7\n",
      "INFO: training with the images batch#8\n",
      "INFO: training with the images batch#9\n",
      "INFO: training with the images batch#10\n",
      "INFO: training with the images batch#11\n",
      "INFO: testing time: \t2.425304651260376\n",
      "INFO: average cross entropy per batch: \t13.685547242561976\n",
      "INFO: average cluster loss per batch: \t0.0007620414035045542\n",
      "INFO: separation loss:\t0.0006374120791103147\n",
      "INFO: avged separation loss:\t0.1538341330985228\n",
      "INFO: accu: \t38.333333333333336%\n",
      "INFO:epoch: \t11\n",
      "INFO: training with the images batch#0\n",
      "INFO: training with the images batch#1\n",
      "INFO: training with the images batch#2\n",
      "INFO: training with the images batch#3\n",
      "INFO: training with the images batch#4\n",
      "INFO: training with the images batch#5\n",
      "INFO: training with the images batch#6\n",
      "INFO: training with the images batch#7\n",
      "INFO: training with the images batch#8\n",
      "INFO: training with the images batch#9\n",
      "INFO: training with the images batch#10\n",
      "INFO: training with the images batch#11\n",
      "INFO: training time: \t7.5341339111328125\n",
      "INFO: average cross entropy per batch: \t2.756815063456694\n",
      "INFO: average cluster loss per batch: \t0.0024934212366739907\n",
      "INFO: separation loss:\t0.0033167202655022265\n",
      "INFO: avged separation loss:\t0.20266176636020342\n",
      "INFO: accu: \t60.0%\n",
      "INFO: training with the images batch#0\n",
      "INFO: training with the images batch#1\n",
      "INFO: training with the images batch#2\n",
      "INFO: training with the images batch#3\n",
      "INFO: training with the images batch#4\n",
      "INFO: training with the images batch#5\n",
      "INFO: training with the images batch#6\n",
      "INFO: training with the images batch#7\n",
      "INFO: training with the images batch#8\n",
      "INFO: training with the images batch#9\n",
      "INFO: training with the images batch#10\n",
      "INFO: training with the images batch#11\n",
      "INFO: testing time: \t2.3149731159210205\n",
      "INFO: average cross entropy per batch: \t3.3507518619298935\n",
      "INFO: average cluster loss per batch: \t0.00208874543083463\n",
      "INFO: separation loss:\t0.0020400921030159225\n",
      "INFO: avged separation loss:\t0.2112086017926534\n",
      "INFO: accu: \t46.666666666666664%\n",
      "INFO:epoch: \t12\n",
      "INFO: training with the images batch#0\n",
      "INFO: training with the images batch#1\n",
      "INFO: training with the images batch#2\n",
      "INFO: training with the images batch#3\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 22\u001b[39m\n\u001b[32m     20\u001b[39m     tnt_joint(model=ppnet, log=log)\n\u001b[32m     21\u001b[39m     joint_lr_scheduler.step()\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m     _ = \u001b[43mtnt_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mppnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mjoint_optimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m                  \u001b[49m\u001b[43mclass_specific\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclass_specific\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcoefs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcoefs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlog\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     25\u001b[39m accu = tnt_test(model=ppnet, dataloader=test_loader,\n\u001b[32m     26\u001b[39m                 class_specific=class_specific, log=log)\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m epoch >= push_start \u001b[38;5;129;01mand\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m push_epochs:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 84\u001b[39m, in \u001b[36mtnt_train\u001b[39m\u001b[34m(model, dataloader, optimizer, class_specific, coefs, log)\u001b[39m\n\u001b[32m     82\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m(optimizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)    \n\u001b[32m     83\u001b[39m model.train()\n\u001b[32m---> \u001b[39m\u001b[32m84\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_train_or_test\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     85\u001b[39m \u001b[43m                      \u001b[49m\u001b[43mclass_specific\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclass_specific\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcoefs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcoefs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlog\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 61\u001b[39m, in \u001b[36m_train_or_test\u001b[39m\u001b[34m(model, dataloader, optimizer, class_specific, coefs, log)\u001b[39m\n\u001b[32m     59\u001b[39m     optimizer.zero_grad()\n\u001b[32m     60\u001b[39m     loss.backward()\n\u001b[32m---> \u001b[39m\u001b[32m61\u001b[39m     \u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     63\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m input_imag\n\u001b[32m     64\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m target_class\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:124\u001b[39m, in \u001b[36mLRScheduler.__init__.<locals>.patch_track_step_called.<locals>.wrap_step.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    122\u001b[39m opt = opt_ref()\n\u001b[32m    123\u001b[39m opt._opt_called = \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m124\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__get__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__class__\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/torch/optim/optimizer.py:485\u001b[39m, in \u001b[36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    480\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    481\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    482\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    483\u001b[39m             )\n\u001b[32m--> \u001b[39m\u001b[32m485\u001b[39m out = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    486\u001b[39m \u001b[38;5;28mself\u001b[39m._optimizer_step_code()\n\u001b[32m    488\u001b[39m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/torch/optim/optimizer.py:79\u001b[39m, in \u001b[36m_use_grad_for_differentiable.<locals>._use_grad\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     77\u001b[39m     torch.set_grad_enabled(\u001b[38;5;28mself\u001b[39m.defaults[\u001b[33m\"\u001b[39m\u001b[33mdifferentiable\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     78\u001b[39m     torch._dynamo.graph_break()\n\u001b[32m---> \u001b[39m\u001b[32m79\u001b[39m     ret = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     80\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     81\u001b[39m     torch._dynamo.graph_break()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/torch/optim/adam.py:246\u001b[39m, in \u001b[36mAdam.step\u001b[39m\u001b[34m(self, closure)\u001b[39m\n\u001b[32m    234\u001b[39m     beta1, beta2 = group[\u001b[33m\"\u001b[39m\u001b[33mbetas\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    236\u001b[39m     has_complex = \u001b[38;5;28mself\u001b[39m._init_group(\n\u001b[32m    237\u001b[39m         group,\n\u001b[32m    238\u001b[39m         params_with_grad,\n\u001b[32m   (...)\u001b[39m\u001b[32m    243\u001b[39m         state_steps,\n\u001b[32m    244\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m246\u001b[39m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    247\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    248\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    249\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    250\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mamsgrad\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    256\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    257\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    258\u001b[39m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweight_decay\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    259\u001b[39m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43meps\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    260\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmaximize\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    261\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mforeach\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    262\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcapturable\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    263\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdifferentiable\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    264\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfused\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    265\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgrad_scale\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    266\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfound_inf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    267\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdecoupled_weight_decay\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    268\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    270\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/torch/optim/optimizer.py:147\u001b[39m, in \u001b[36m_disable_dynamo_if_unsupported.<locals>.wrapper.<locals>.maybe_fallback\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    145\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m disabled_func(*args, **kwargs)\n\u001b[32m    146\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/torch/optim/adam.py:933\u001b[39m, in \u001b[36madam\u001b[39m\u001b[34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, decoupled_weight_decay, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[39m\n\u001b[32m    930\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    931\u001b[39m     func = _single_tensor_adam\n\u001b[32m--> \u001b[39m\u001b[32m933\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    934\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    935\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    936\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    937\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    938\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    939\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    940\u001b[39m \u001b[43m    \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m=\u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    941\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    942\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    943\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    944\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    945\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    946\u001b[39m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[43m=\u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    947\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    948\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    949\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    950\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    951\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    952\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    953\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/torch/optim/adam.py:414\u001b[39m, in \u001b[36m_single_tensor_adam\u001b[39m\u001b[34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable, decoupled_weight_decay)\u001b[39m\n\u001b[32m    412\u001b[39m                 grad = grad.add(param, alpha=weight_decay)\n\u001b[32m    413\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m414\u001b[39m             grad = \u001b[43mgrad\u001b[49m\u001b[43m.\u001b[49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    416\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch.is_complex(param):\n\u001b[32m    417\u001b[39m     grad = torch.view_as_real(grad)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "log('INFO: start training the model ......')\n",
    "num_train_epochs = 1000\n",
    "num_warm_epochs = 5\n",
    "\n",
    "push_start = 10\n",
    "push_epochs = [i for i in range(num_train_epochs) if i % 10 == 0]\n",
    "\n",
    "coefs = {'crs_ent': 1, 'clst': 0.8, 'sep': -0.08, 'l1': 1e-4}\n",
    "class_specific = True\n",
    "\n",
    "for epoch in range(num_train_epochs):\n",
    "    log('INFO:epoch: \\t{0}'.format(epoch))\n",
    "\n",
    "    if epoch < num_warm_epochs:\n",
    "        tnt_warm_only(model=ppnet, log=log)\n",
    "        _ = tnt_train(model=ppnet, dataloader=train_loader, optimizer=warm_optimizer,\n",
    "                      class_specific=class_specific, coefs=coefs, log=log)\n",
    "    else:\n",
    "        tnt_joint(model=ppnet, log=log)\n",
    "        joint_lr_scheduler.step()\n",
    "        _ = tnt_train(model=ppnet, dataloader=train_loader, optimizer=joint_optimizer,\n",
    "                      class_specific=class_specific, coefs=coefs, log=log)\n",
    "\n",
    "    accu = tnt_test(model=ppnet, dataloader=test_loader,\n",
    "                    class_specific=class_specific, log=log)\n",
    "\n",
    "    if epoch >= push_start and epoch in push_epochs:\n",
    "        push_prototypes(\n",
    "            train_push_loader, # pytorch dataloader (must be unnormalized in [0,1])\n",
    "            prototype_network=ppnet, # pytorch network with prototype_vectors\n",
    "            class_specific=class_specific,\n",
    "            preprocess_input_function=preprocess_input_function, # normalize if needed\n",
    "            prototype_layer_stride=1,\n",
    "            root_dir_for_saving_prototypes=img_dir, # if not None, prototypes will be saved here\n",
    "            epoch_number=epoch, # if not provided, prototypes saved previously will be overwritten\n",
    "            prototype_img_filename_prefix=prototype_img_filename_prefix,\n",
    "            prototype_self_act_filename_prefix=prototype_self_act_filename_prefix,\n",
    "            proto_bound_boxes_filename_prefix=proto_bound_boxes_filename_prefix,\n",
    "            save_prototype_class_identity=True,\n",
    "            log=log)\n",
    "        accu = tnt_test(model=ppnet, dataloader=test_loader,\n",
    "                        class_specific=class_specific, log=log)\n",
    "\n",
    "        if prototype_activation_function != 'linear':\n",
    "            tnt_last_only(model=ppnet, log=log)\n",
    "            for i in range(20):\n",
    "                _ = tnt_train(model=ppnet, dataloader=train_loader, optimizer=h_last_layer_optimizer,\n",
    "                              class_specific=class_specific, coefs=coefs, log=log)\n",
    "                accu = tnt_test(model=ppnet, dataloader=test_loader,\n",
    "                                class_specific=class_specific, log=log)\n",
    "\n",
    "logclose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f187b8-ae2e-4d37-92c6-9f77e28050b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
