{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "373e7e6c-daea-422d-b595-11caff0d6b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "import torch\n",
    "import torch.utils.data\n",
    "\n",
    "import argparse\n",
    "import re\n",
    "\n",
    "from helpers import makedir\n",
    "import push\n",
    "import prune\n",
    "import save\n",
    "from log import create_logger\n",
    "from preprocess import mean, std, preprocess_input_function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4bffefa-ef03-4e19-85aa-5fed7358dbca",
   "metadata": {},
   "outputs": [],
   "source": [
    "## setting\n",
    "prototype_shape = (128, 8, 1, 1)\n",
    "num_classes = 2\n",
    "prototype_activation_function = 'log'\n",
    "add_on_layers_type = 'regular'\n",
    "\n",
    "experiment_run = '003'\n",
    "\n",
    "joint_optimizer_lrs = {'features': 1e-4,\n",
    "                       'add_on_layers': 3e-3,\n",
    "                       'prototype_vectors': 3e-3}\n",
    "joint_lr_step_size = 5\n",
    "\n",
    "warm_optimizer_lrs = {'add_on_layers': 3e-3,\n",
    "                      'prototype_vectors': 3e-3}\n",
    "\n",
    "last_layer_optimizer_lr = 1e-4\n",
    "\n",
    "coefs = {\n",
    "    'crs_ent': 1,\n",
    "    'clst': 0.8,\n",
    "    'sep': -0.08,\n",
    "    'l1': 1e-4,\n",
    "}\n",
    "\n",
    "num_train_epochs = 1000\n",
    "num_warm_epochs = 5\n",
    "\n",
    "push_start = 10\n",
    "push_epochs = [i for i in range(num_train_epochs) if i % 10 == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a539a78-f0b7-4ee9-9e25-e35691112f50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base_architecture: vgg19\n",
      "base_architecture_type: vgg\n",
      "mode_dir: ./saved_models/vgg19/003/\n",
      "saved main.ipynb to /home/jovyan/codes/ProtoPNet/main.ipynb\n",
      "train dir: ./datasets/cub200_cropped/train_cropped_augmented/\n",
      "test_dir: ./datasets/cub200_cropped/test_cropped/\n",
      "train_push_dir: ./datasets/cub200_cropped/train_cropped/\n"
     ]
    }
   ],
   "source": [
    "## settings\n",
    "base_architecture = 'vgg19'\n",
    "base_architecture_type = re.match('^[a-z]*', base_architecture).group(0)\n",
    "\n",
    "model_dir = './saved_models/' + base_architecture + '/' + experiment_run + '/'\n",
    "makedir(model_dir)\n",
    "\n",
    "my_filepath = os.path.join(os.getcwd(), 'main.ipynb') \n",
    "shutil.copy(src=my_filepath, dst=model_dir)\n",
    "\n",
    "log, logclose = create_logger(log_filename=os.path.join(model_dir, 'train.log'))\n",
    "img_dir = os.path.join(model_dir, 'img')\n",
    "makedir(img_dir)\n",
    "weight_matrix_filename = 'outputL_weights'\n",
    "prototype_img_filename_prefix = 'prototype-img'\n",
    "prototype_self_act_filename_prefix = 'prototype-self-act'\n",
    "proto_bound_boxes_filename_prefix = 'bb'\n",
    "\n",
    "log('base_architecture: {0}'.format(base_architecture))\n",
    "log('base_architecture_type: {0}'.format(base_architecture_type))\n",
    "log('mode_dir: {0}'.format(model_dir))\n",
    "log('saved main.ipynb to {0}'.format(my_filepath))\n",
    "\n",
    "data_path = './datasets/cub200_cropped/'\n",
    "train_dir = data_path + 'train_cropped_augmented/'\n",
    "test_dir = data_path + 'test_cropped/'\n",
    "train_push_dir = data_path + 'train_cropped/'\n",
    "\n",
    "log('train dir: {0}'.format(train_dir))\n",
    "log('test_dir: {0}'.format(test_dir))\n",
    "log('train_push_dir: {0}'.format(train_push_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0a13ed7-2725-4ea5-a807-5bb4da6ed39a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set size: 60\n",
      "push set size: 60\n",
      "test set size: 60\n",
      "batch size: 5\n"
     ]
    }
   ],
   "source": [
    "## load the dataset\n",
    "\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "img_size = 56\n",
    "train_batch_size = 5\n",
    "test_batch_size = 5\n",
    "train_push_batch_size = 5\n",
    "\n",
    "normalize = transforms.Normalize(mean=mean, std=std)\n",
    "\n",
    "train_dataset = datasets.ImageFolder(\n",
    "    train_dir,\n",
    "    transforms.Compose([\n",
    "        transforms.Resize(size=(img_size, img_size)),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]))\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=train_batch_size, shuffle=True,\n",
    "    num_workers=0, pin_memory=False)\n",
    "# push set\n",
    "train_push_dataset = datasets.ImageFolder(\n",
    "    train_push_dir,\n",
    "    transforms.Compose([\n",
    "        transforms.Resize(size=(img_size, img_size)),\n",
    "        transforms.ToTensor(),\n",
    "    ]))\n",
    "train_push_loader = torch.utils.data.DataLoader(\n",
    "    train_push_dataset, batch_size=train_push_batch_size, shuffle=False,\n",
    "    num_workers=0, pin_memory=False)\n",
    "# test set\n",
    "test_dataset = datasets.ImageFolder(\n",
    "    test_dir,\n",
    "    transforms.Compose([\n",
    "        transforms.Resize(size=(img_size, img_size)),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]))\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset, batch_size=test_batch_size, shuffle=False,\n",
    "    num_workers=0, pin_memory=False)\n",
    "\n",
    "# we should look into distributed sampler more carefully at torch.utils.data.distributed.DistributedSampler(train_dataset)\n",
    "log('training set size: {0}'.format(len(train_loader.dataset)))\n",
    "log('push set size: {0}'.format(len(train_push_loader.dataset)))\n",
    "log('test set size: {0}'.format(len(test_loader.dataset)))\n",
    "log('batch size: {0}'.format(train_batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "600f91f4-fc3c-484c-8195-0424d0e6f54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## vgg_features\n",
    "import torch.nn as nn\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "\n",
    "class VGG_features(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super(VGG_features, self).__init__()\n",
    "        self.kernel_sizes = []\n",
    "        self.strides = []\n",
    "        self.paddings = []\n",
    "        self.features = self._make_layers(cfg)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        return x\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def _make_layers(self, cfg):\n",
    "        self.n_layers = 0\n",
    "        layers = []\n",
    "        in_channels = 3\n",
    "        for v in cfg:\n",
    "            if v == 'M':\n",
    "                layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "                self.kernel_sizes.append(2)\n",
    "                self.strides.append(2)\n",
    "                self.paddings.append(0)\n",
    "            else:\n",
    "                conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)\n",
    "                layers += [conv2d, nn.ReLU(inplace=True)]\n",
    "                self.n_layers += 1\n",
    "                self.kernel_sizes.append(3)\n",
    "                self.strides.append(1)\n",
    "                self.paddings.append(1)\n",
    "                in_channels = v\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def conv_info(self):\n",
    "        return self.kernel_sizes, self.strides, self.paddings\n",
    "\n",
    "    def num_layers(self):\n",
    "        '''\n",
    "        the number of conv layers in the network\n",
    "        '''\n",
    "        return self.n_layers\n",
    "\n",
    "    def __repr__(self):\n",
    "        template = 'VGG{}'\n",
    "        return template.format(self.num_layers() + 3)\n",
    "\n",
    "def vgg19_features():\n",
    "    \"\"\"VGG 19-layer model\n",
    "    \"\"\"\n",
    "    cfg = [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M']\n",
    "    model = VGG_features(cfg)\n",
    "    my_dict = model_zoo.load_url('https://download.pytorch.org/models/vgg19-dcbb9e9d.pth', model_dir='./pretrained_models')\n",
    "    keys_to_remove = set()\n",
    "    \n",
    "    for key in my_dict:\n",
    "        if key.startswith('classifier'):\n",
    "            keys_to_remove.add(key)\n",
    "    for key in keys_to_remove:\n",
    "        del my_dict[key]\n",
    "    model.load_state_dict(my_dict, strict=False)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d6626c6-354c-46c6-b067-df80ed02c4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## model\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "import torch.nn.functional as F\n",
    "from receptive_field import compute_proto_layer_rf_info_v2\n",
    "\n",
    "class PPNet(nn.Module):\n",
    "\n",
    "    def __init__(self, features, img_size, prototype_shape,\n",
    "                 proto_layer_rf_info, num_classes,\n",
    "                 prototype_activation_function='log',\n",
    "                 add_on_layers_type='bottleneck'):\n",
    "\n",
    "        super(PPNet, self).__init__()\n",
    "        self.img_size = img_size\n",
    "        self.prototype_shape = prototype_shape\n",
    "        self.num_prototypes = prototype_shape[0]\n",
    "        self.num_classes = num_classes\n",
    "        self.epsilon = 1e-4\n",
    "        \n",
    "        # prototype_activation_function could be 'log', 'linear',\n",
    "        # or a generic function that converts distance to similarity score\n",
    "        self.prototype_activation_function = prototype_activation_function\n",
    "\n",
    "        '''\n",
    "        Here we are initializing the class identities of the prototypes\n",
    "        Without domain specific knowledge we allocate the same number of\n",
    "        prototypes for each class\n",
    "        '''\n",
    "        assert(self.num_prototypes % self.num_classes == 0)\n",
    "        # a onehot indication matrix for each prototype's class identity\n",
    "        self.prototype_class_identity = torch.zeros(self.num_prototypes,\n",
    "                                                    self.num_classes)\n",
    "\n",
    "        num_prototypes_per_class = self.num_prototypes // self.num_classes\n",
    "        for j in range(self.num_prototypes):\n",
    "            self.prototype_class_identity[j, j // num_prototypes_per_class] = 1\n",
    "\n",
    "        self.proto_layer_rf_info = proto_layer_rf_info\n",
    "\n",
    "        # this has to be named features to allow the precise loading\n",
    "        self.features = features\n",
    "        first_add_on_layer_in_channels = [i for i in features.modules() if isinstance(i, nn.Conv2d)][-1].out_channels\n",
    "\n",
    "        self.add_on_layers = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=first_add_on_layer_in_channels, out_channels=self.prototype_shape[1], kernel_size=1),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(in_channels=self.prototype_shape[1], out_channels=self.prototype_shape[1], kernel_size=1),\n",
    "                nn.Sigmoid()\n",
    "                )\n",
    "        \n",
    "        self.prototype_vectors = nn.Parameter(torch.rand(self.prototype_shape),\n",
    "                                              requires_grad=True)\n",
    "\n",
    "        self.ones = nn.Parameter(torch.ones(self.prototype_shape),\n",
    "                                 requires_grad=False)\n",
    "\n",
    "        self.last_layer = nn.Linear(self.num_prototypes, self.num_classes,\n",
    "                                    bias=False) # do not use bias\n",
    "\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def conv_features(self, x):\n",
    "        '''\n",
    "        the feature input to prototype layer\n",
    "        '''\n",
    "        x = self.features(x)\n",
    "        x = self.add_on_layers(x)\n",
    "        return x\n",
    "\n",
    "    def _l2_convolution(self, x):\n",
    "        '''\n",
    "        apply self.prototype_vectors as l2-convolution filters on input x\n",
    "        '''\n",
    "        x2 = x ** 2\n",
    "        x2_patch_sum = F.conv2d(input=x2, weight=self.ones)\n",
    "\n",
    "        p2 = self.prototype_vectors ** 2\n",
    "        p2 = torch.sum(p2, dim=(1, 2, 3))\n",
    "        # p2 is a vector of shape (num_prototypes,)\n",
    "        # then we reshape it to (num_prototypes, 1, 1)\n",
    "        p2_reshape = p2.view(-1, 1, 1)\n",
    "\n",
    "        xp = F.conv2d(input=x, weight=self.prototype_vectors)\n",
    "        intermediate_result = - 2 * xp + p2_reshape  # use broadcast\n",
    "        # x2_patch_sum and intermediate_result are of the same shape\n",
    "        distances = F.relu(x2_patch_sum + intermediate_result)\n",
    "\n",
    "        return distances\n",
    "\n",
    "    def prototype_distances(self, x):\n",
    "        '''\n",
    "        x is the raw input\n",
    "        '''\n",
    "        conv_features = self.conv_features(x)\n",
    "        distances = self._l2_convolution(conv_features)\n",
    "        return distances\n",
    "\n",
    "    def distance_2_similarity(self, distances):\n",
    "        if self.prototype_activation_function == 'log':\n",
    "            return torch.log((distances + 1) / (distances + self.epsilon))\n",
    "        elif self.prototype_activation_function == 'linear':\n",
    "            return -distances\n",
    "        else:\n",
    "            return self.prototype_activation_function(distances)\n",
    "\n",
    "    def forward(self, x):\n",
    "        distances = self.prototype_distances(x)\n",
    "        '''\n",
    "        we cannot refactor the lines below for similarity scores\n",
    "        because we need to return min_distances\n",
    "        '''\n",
    "        # global min pooling\n",
    "        min_distances = -F.max_pool2d(-distances,\n",
    "                                      kernel_size=(distances.size()[2],\n",
    "                                                   distances.size()[3]))\n",
    "        min_distances = min_distances.view(-1, self.num_prototypes)\n",
    "        prototype_activations = self.distance_2_similarity(min_distances)\n",
    "        logits = self.last_layer(prototype_activations)\n",
    "        return logits, min_distances\n",
    "\n",
    "    def push_forward(self, x):\n",
    "        '''this method is needed for the pushing operation'''\n",
    "        conv_output = self.conv_features(x)\n",
    "        distances = self._l2_convolution(conv_output)\n",
    "        return conv_output, distances\n",
    "\n",
    "    def prune_prototypes(self, prototypes_to_prune):\n",
    "        '''\n",
    "        prototypes_to_prune: a list of indices each in\n",
    "        [0, current number of prototypes - 1] that indicates the prototypes to\n",
    "        be removed\n",
    "        '''\n",
    "        prototypes_to_keep = list(set(range(self.num_prototypes)) - set(prototypes_to_prune))\n",
    "\n",
    "        self.prototype_vectors = nn.Parameter(self.prototype_vectors.data[prototypes_to_keep, ...],\n",
    "                                              requires_grad=True)\n",
    "\n",
    "        self.prototype_shape = list(self.prototype_vectors.size())\n",
    "        self.num_prototypes = self.prototype_shape[0]\n",
    "\n",
    "        # changing self.last_layer in place\n",
    "        # changing in_features and out_features make sure the numbers are consistent\n",
    "        self.last_layer.in_features = self.num_prototypes\n",
    "        self.last_layer.out_features = self.num_classes\n",
    "        self.last_layer.weight.data = self.last_layer.weight.data[:, prototypes_to_keep]\n",
    "\n",
    "        # self.ones is nn.Parameter\n",
    "        self.ones = nn.Parameter(self.ones.data[prototypes_to_keep, ...],\n",
    "                                 requires_grad=False)\n",
    "        # self.prototype_class_identity is torch tensor\n",
    "        # so it does not need .data access for value update\n",
    "        self.prototype_class_identity = self.prototype_class_identity[prototypes_to_keep, :]\n",
    "\n",
    "    def __repr__(self):\n",
    "        # PPNet(self, features, img_size, prototype_shape,\n",
    "        # proto_layer_rf_info, num_classes, init_weights=True):\n",
    "        rep = (\n",
    "            'PPNet(\\n'\n",
    "            '\\tfeatures: {},\\n'\n",
    "            '\\timg_size: {},\\n'\n",
    "            '\\tprototype_shape: {},\\n'\n",
    "            '\\tproto_layer_rf_info: {},\\n'\n",
    "            '\\tnum_classes: {},\\n'\n",
    "            '\\tepsilon: {}\\n'\n",
    "            ')'\n",
    "        )\n",
    "\n",
    "        return rep.format(self.features,\n",
    "                          self.img_size,\n",
    "                          self.prototype_shape,\n",
    "                          self.proto_layer_rf_info,\n",
    "                          self.num_classes,\n",
    "                          self.epsilon)\n",
    "\n",
    "    def set_last_layer_incorrect_connection(self, incorrect_strength):\n",
    "        '''\n",
    "        the incorrect strength will be actual strength if -0.5 then input -0.5\n",
    "        '''\n",
    "        positive_one_weights_locations = torch.t(self.prototype_class_identity)\n",
    "        negative_one_weights_locations = 1 - positive_one_weights_locations\n",
    "\n",
    "        correct_class_connection = 1\n",
    "        incorrect_class_connection = incorrect_strength\n",
    "        self.last_layer.weight.data.copy_(\n",
    "            correct_class_connection * positive_one_weights_locations\n",
    "            + incorrect_class_connection * negative_one_weights_locations)\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.add_on_layers.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                # every init technique has an underscore _ in the name\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "\n",
    "        self.set_last_layer_incorrect_connection(incorrect_strength=-0.5)\n",
    "\n",
    "\n",
    "\n",
    "def construct_PPNet(base_architecture, pretrained=True, img_size=224,\n",
    "                    prototype_shape=(2000, 512, 1, 1), num_classes=200,\n",
    "                    prototype_activation_function='log',\n",
    "                    add_on_layers_type='bottleneck'):\n",
    "    features = vgg19_features()\n",
    "    layer_filter_sizes, layer_strides, layer_paddings = features.conv_info()\n",
    "    proto_layer_rf_info = compute_proto_layer_rf_info_v2(img_size=img_size,\n",
    "                                                         layer_filter_sizes=layer_filter_sizes,\n",
    "                                                         layer_strides=layer_strides,\n",
    "                                                         layer_paddings=layer_paddings,\n",
    "                                                         prototype_kernel_size=prototype_shape[2])\n",
    "    return PPNet(features=features,\n",
    "                 img_size=img_size,\n",
    "                 prototype_shape=prototype_shape,\n",
    "                 proto_layer_rf_info=proto_layer_rf_info,\n",
    "                 num_classes=num_classes,\n",
    "                 prototype_activation_function=prototype_activation_function,\n",
    "                 add_on_layers_type=add_on_layers_type)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50439f05-39ae-4f10-9c87-6a8b251253a3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# construct the model\n",
    "ppnet = construct_PPNet(base_architecture=base_architecture,\n",
    "                              pretrained=True, img_size=img_size,\n",
    "                              prototype_shape=prototype_shape,\n",
    "                              num_classes=num_classes,\n",
    "                              prototype_activation_function=prototype_activation_function,\n",
    "                              add_on_layers_type=add_on_layers_type)\n",
    "\n",
    "class_specific = True\n",
    "\n",
    "# define optimizer\n",
    "joint_optimizer_specs = \\\n",
    "[{'params': ppnet.features.parameters(), 'lr': joint_optimizer_lrs['features'], 'weight_decay': 1e-3}, # bias are now also being regularized\n",
    " {'params': ppnet.add_on_layers.parameters(), 'lr': joint_optimizer_lrs['add_on_layers'], 'weight_decay': 1e-3},\n",
    " {'params': ppnet.prototype_vectors, 'lr': joint_optimizer_lrs['prototype_vectors']},\n",
    "]\n",
    "joint_optimizer = torch.optim.Adam(joint_optimizer_specs)\n",
    "joint_lr_scheduler = torch.optim.lr_scheduler.StepLR(joint_optimizer, step_size=joint_lr_step_size, gamma=0.1)\n",
    "\n",
    "warm_optimizer_specs = \\\n",
    "[{'params': ppnet.add_on_layers.parameters(), 'lr': warm_optimizer_lrs['add_on_layers'], 'weight_decay': 1e-3},\n",
    " {'params': ppnet.prototype_vectors, 'lr': warm_optimizer_lrs['prototype_vectors']},\n",
    "]\n",
    "warm_optimizer = torch.optim.Adam(warm_optimizer_specs)\n",
    "\n",
    "last_layer_optimizer_specs = [{'params': ppnet.last_layer.parameters(), 'lr': last_layer_optimizer_lr}]\n",
    "last_layer_optimizer = torch.optim.Adam(last_layer_optimizer_specs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a224a04b-b253-4223-b6a0-944c9236d121",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "\n",
    "from helpers import list_of_distances, make_one_hot\n",
    "\n",
    "def _train_or_test(model, dataloader, optimizer=None, class_specific=True, use_l1_mask=True,\n",
    "                   coefs=None, log=print):\n",
    "    '''\n",
    "    model: the multi-gpu model\n",
    "    dataloader:\n",
    "    optimizer: if None, will be test evaluation\n",
    "    '''\n",
    "    is_train = optimizer is not None\n",
    "    start = time.time()\n",
    "    n_examples = 0\n",
    "    n_correct = 0\n",
    "    n_batches = 0\n",
    "    total_cross_entropy = 0\n",
    "    total_cluster_cost = 0\n",
    "    # separation cost is meaningful only for class_specific\n",
    "    total_separation_cost = 0\n",
    "    total_avg_separation_cost = 0\n",
    "\n",
    "    for i, (image, label) in enumerate(dataloader):\n",
    "        # input = image.cuda()\n",
    "        # target = label.cuda()\n",
    "        input = image # .cuda()\n",
    "        target = label # .cuda()\n",
    "        log('\\t i={0}'.format(i))\n",
    "        # torch.enable_grad() has no effect outside of no_grad()\n",
    "        grad_req = torch.enable_grad() if is_train else torch.no_grad()\n",
    "        log('\\t with grad_req:')\n",
    "        with grad_req:\n",
    "            # nn.Module has implemented __call__() function\n",
    "            # so no need to call .forward\n",
    "            log('\\t output, min_distances = model(input)')\n",
    "            output, min_distances = model(input)\n",
    "\n",
    "            # compute loss\n",
    "            log('\\t cross_entropy = torch.nn.functional.cross_entropy(output, target)')\n",
    "            cross_entropy = torch.nn.functional.cross_entropy(output, target)\n",
    "\n",
    "            if class_specific:\n",
    "                log('\\t max_dist = (ppnet.prototype_shape[1]')\n",
    "                max_dist = (ppnet.prototype_shape[1]\n",
    "                            * ppnet.prototype_shape[2]\n",
    "                            * ppnet.prototype_shape[3])\n",
    "\n",
    "                # prototypes_of_correct_class is a tensor of shape batch_size * num_prototypes\n",
    "                # calculate cluster cost\n",
    "                # prototypes_of_correct_class = torch.t(ppnet.prototype_class_identity[:,label]).cuda()\n",
    "                log('\\t prototypes_of_correct_class = torch.t(ppnet.prototype_class_identity[:,label])')\n",
    "                prototypes_of_correct_class = torch.t(ppnet.prototype_class_identity[:,label])\n",
    "                log('\\t inverted_distances, _ = torch.max((max_dist - min_distances) * prototypes_of_correct_class, dim=1)')\n",
    "                inverted_distances, _ = torch.max((max_dist - min_distances) * prototypes_of_correct_class, dim=1)\n",
    "                log('\\t cluster_cost = torch.mean(max_dist - inverted_distances)')\n",
    "                cluster_cost = torch.mean(max_dist - inverted_distances)\n",
    "\n",
    "                # calculate separation cost\n",
    "                log('\\t prototypes_of_wrong_class = 1 - prototypes_of_correct_class')\n",
    "                prototypes_of_wrong_class = 1 - prototypes_of_correct_class\n",
    "                log('\\t inverted_distances_to_nontarget_prototypes, _ = ')\n",
    "                inverted_distances_to_nontarget_prototypes, _ = \\\n",
    "                    torch.max((max_dist - min_distances) * prototypes_of_wrong_class, dim=1)\n",
    "                log('\\t separation_cost = torch.mean(max_dist - inverted_distances_to_nontarget_prototypes)')\n",
    "                separation_cost = torch.mean(max_dist - inverted_distances_to_nontarget_prototypes)\n",
    "\n",
    "                # calculate avg cluster cost\n",
    "                log('\\t avg_separation_cost = ')\n",
    "                avg_separation_cost = \\\n",
    "                    torch.sum(min_distances * prototypes_of_wrong_class, dim=1) / torch.sum(prototypes_of_wrong_class, dim=1)\n",
    "                log('\\t avg_separation_cost = torch.mean(avg_separation_cost)')\n",
    "                avg_separation_cost = torch.mean(avg_separation_cost)\n",
    "                \n",
    "                if use_l1_mask:\n",
    "                    #l1_mask = 1 - torch.t(ppnet.prototype_class_identity).cuda()\n",
    "                    log('\\t l1_mask = 1 - torch.t(ppnet.prototype_class_identity) ')\n",
    "                    l1_mask = 1 - torch.t(ppnet.prototype_class_identity) \n",
    "                    log('\\t l1 = (ppnet.last_layer.weight * l1_mask).norm(p=1)')\n",
    "                    l1 = (ppnet.last_layer.weight * l1_mask).norm(p=1)\n",
    "                else:\n",
    "                    log('\\t l1 = ppnet.last_layer.weight.norm(p=1) ')\n",
    "                    l1 = ppnet.last_layer.weight.norm(p=1) \n",
    "\n",
    "            else:\n",
    "                log('\\t min_distance, _ = torch.min(min_distances, dim=1)')\n",
    "                min_distance, _ = torch.min(min_distances, dim=1)\n",
    "                log('\\t luster_cost = torch.mean(min_distance)')\n",
    "                cluster_cost = torch.mean(min_distance)\n",
    "                log('\\t l1 = ppnet.last_layer.weight.norm(p=1)')\n",
    "                l1 = ppnet.last_layer.weight.norm(p=1)\n",
    "\n",
    "            # evaluation statistics\n",
    "            log('\\t _, predicted = torch.max(output.data, 1)')\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            log('\\t n_examples += target.size(0)')\n",
    "            n_examples += target.size(0)\n",
    "            log('\\t n_correct += (predicted == target).sum().item()')\n",
    "            n_correct += (predicted == target).sum().item()\n",
    "\n",
    "            n_batches += 1\n",
    "            total_cross_entropy += cross_entropy.item()\n",
    "            total_cluster_cost += cluster_cost.item()\n",
    "            total_separation_cost += separation_cost.item()\n",
    "            total_avg_separation_cost += avg_separation_cost.item()\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        if is_train:\n",
    "            if class_specific:\n",
    "                if coefs is not None:\n",
    "                    loss = (coefs['crs_ent'] * cross_entropy\n",
    "                          + coefs['clst'] * cluster_cost\n",
    "                          + coefs['sep'] * separation_cost\n",
    "                          + coefs['l1'] * l1)\n",
    "                else:\n",
    "                    loss = cross_entropy + 0.8 * cluster_cost - 0.08 * separation_cost + 1e-4 * l1\n",
    "            else:\n",
    "                if coefs is not None:\n",
    "                    loss = (coefs['crs_ent'] * cross_entropy\n",
    "                          + coefs['clst'] * cluster_cost\n",
    "                          + coefs['l1'] * l1)\n",
    "                else:\n",
    "                    loss = cross_entropy + 0.8 * cluster_cost + 1e-4 * l1\n",
    "            log('\\t optimizer.zero_grad()')\n",
    "            optimizer.zero_grad()\n",
    "            log('\\t loss.backward()')\n",
    "            loss.backward()\n",
    "            log('\\t optimizer.step()')\n",
    "            optimizer.step()\n",
    "\n",
    "        del input\n",
    "        del target\n",
    "        del output\n",
    "        del predicted\n",
    "        del min_distances\n",
    "\n",
    "    end = time.time()\n",
    "\n",
    "    log('\\ttime: \\t{0}'.format(end -  start))\n",
    "    log('\\tcross ent: \\t{0}'.format(total_cross_entropy / n_batches))\n",
    "    log('\\tcluster: \\t{0}'.format(total_cluster_cost / n_batches))\n",
    "    if class_specific:\n",
    "        log('\\tseparation:\\t{0}'.format(total_separation_cost / n_batches))\n",
    "        log('\\tavg separation:\\t{0}'.format(total_avg_separation_cost / n_batches))\n",
    "    log('\\taccu: \\t\\t{0}%'.format(n_correct / n_examples * 100))\n",
    "    log('\\tl1: \\t\\t{0}'.format(ppnet.last_layer.weight.norm(p=1).item()))\n",
    "    p = ppnet.prototype_vectors.view(ppnet.num_prototypes, -1)# .cpu()\n",
    "    log('\\tp')\n",
    "    # with torch.no_grad():\n",
    "    #     p_avg_pair_dist = torch.mean(list_of_distances(p, p))\n",
    "    # log('\\tp dist pair: \\t{0}'.format(p_avg_pair_dist.item()))\n",
    "\n",
    "    return n_correct / n_examples\n",
    "\n",
    "\n",
    "def tnt_train(model, dataloader, optimizer, class_specific=False, coefs=None, log=print):\n",
    "    assert(optimizer is not None)\n",
    "    \n",
    "    log('\\ttrain')\n",
    "    model.train()\n",
    "    log('\\t after model train()')\n",
    "    return _train_or_test(model=model, dataloader=dataloader, optimizer=optimizer,\n",
    "                          class_specific=class_specific, coefs=coefs, log=log)\n",
    "\n",
    "\n",
    "def tnt_test(model, dataloader, class_specific=False, log=print):\n",
    "    log('\\ttest')\n",
    "    model.eval()\n",
    "    return _train_or_test(model=model, dataloader=dataloader, optimizer=None,\n",
    "                          class_specific=class_specific, log=log)\n",
    "\n",
    "\n",
    "def tnt_last_only(model, log=print):\n",
    "    for p in ppnet.features.parameters():\n",
    "        p.requires_grad = False\n",
    "    for p in ppnet.add_on_layers.parameters():\n",
    "        p.requires_grad = False\n",
    "    ppnet.prototype_vectors.requires_grad = False\n",
    "    for p in ppnet.last_layer.parameters():\n",
    "        p.requires_grad = True\n",
    "    \n",
    "    log('\\tlast layer')\n",
    "\n",
    "\n",
    "def tnt_warm_only(model, log=print):\n",
    "    for p in ppnet.features.parameters():\n",
    "        p.requires_grad = False\n",
    "    for p in ppnet.add_on_layers.parameters():\n",
    "        p.requires_grad = True\n",
    "    ppnet.prototype_vectors.requires_grad = True\n",
    "    for p in ppnet.last_layer.parameters():\n",
    "        p.requires_grad = True\n",
    "    \n",
    "    log('\\twarm')\n",
    "\n",
    "\n",
    "def tnt_joint(model, log=print):\n",
    "    for p in ppnet.features.parameters():\n",
    "        p.requires_grad = True\n",
    "    for p in ppnet.add_on_layers.parameters():\n",
    "        p.requires_grad = True\n",
    "    ppnet.prototype_vectors.requires_grad = True\n",
    "    for p in ppnet.last_layer.parameters():\n",
    "        p.requires_grad = True\n",
    "    \n",
    "    log('\\tjoint')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ac8e6a-9bfc-4b90-b1df-dc003711f0ee",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training\n",
      "epoch: \t0\n",
      "\twarm\n",
      "\ttrain\n",
      "\t after model train()\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "log('start training')\n",
    "import copy\n",
    "for epoch in range(num_train_epochs):\n",
    "    log('epoch: \\t{0}'.format(epoch))\n",
    "\n",
    "    if epoch < num_warm_epochs:\n",
    "        tnt_warm_only(model=ppnet, log=log)\n",
    "        _ = tnt_train(model=ppnet, dataloader=train_loader, optimizer=warm_optimizer,\n",
    "                      class_specific=class_specific, coefs=coefs, log=log)\n",
    "    else:\n",
    "        tnt_joint(model=ppnet, log=log)\n",
    "        joint_lr_scheduler.step()\n",
    "        _ = tnt_train(model=ppnet, dataloader=train_loader, optimizer=joint_optimizer,\n",
    "                      class_specific=class_specific, coefs=coefs, log=log)\n",
    "\n",
    "    accu = tnt_test(model=ppnet, dataloader=test_loader,\n",
    "                    class_specific=class_specific, log=log)\n",
    "    save.save_model_w_condition(model=ppnet, model_dir=model_dir, model_name=str(epoch) + 'nopush', accu=accu,\n",
    "                                target_accu=0.70, log=log)\n",
    "\n",
    "    if epoch >= push_start and epoch in push_epochs:\n",
    "        push.push_prototypes(\n",
    "            train_push_loader, # pytorch dataloader (must be unnormalized in [0,1])\n",
    "            prototype_network_parallel=ppnet, # pytorch network with prototype_vectors\n",
    "            class_specific=class_specific,\n",
    "            preprocess_input_function=preprocess_input_function, # normalize if needed\n",
    "            prototype_layer_stride=1,\n",
    "            root_dir_for_saving_prototypes=img_dir, # if not None, prototypes will be saved here\n",
    "            epoch_number=epoch, # if not provided, prototypes saved previously will be overwritten\n",
    "            prototype_img_filename_prefix=prototype_img_filename_prefix,\n",
    "            prototype_self_act_filename_prefix=prototype_self_act_filename_prefix,\n",
    "            proto_bound_boxes_filename_prefix=proto_bound_boxes_filename_prefix,\n",
    "            save_prototype_class_identity=True,\n",
    "            log=log)\n",
    "        accu = tnt_test(model=ppnet, dataloader=test_loader,\n",
    "                        class_specific=class_specific, log=log)\n",
    "        save.save_model_w_condition(model=ppnet, model_dir=model_dir, model_name=str(epoch) + 'push', accu=accu,\n",
    "                                    target_accu=0.70, log=log)\n",
    "\n",
    "        if prototype_activation_function != 'linear':\n",
    "            tnt_last_only(model=ppnet, log=log)\n",
    "            for i in range(20):\n",
    "                log('iteration: \\t{0}'.format(i))\n",
    "                _ = tnt_train(model=ppnet, dataloader=train_loader, optimizer=last_layer_optimizer,\n",
    "                              class_specific=class_specific, coefs=coefs, log=log)\n",
    "                accu = tnt_test(model=ppnet, dataloader=test_loader,\n",
    "                                class_specific=class_specific, log=log)\n",
    "                save.save_model_w_condition(model=ppnet, model_dir=model_dir, model_name=str(epoch) + '_' + str(i) + 'push', accu=accu,\n",
    "                                            target_accu=0.70, log=log)\n",
    "   \n",
    "logclose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f187b8-ae2e-4d37-92c6-9f77e28050b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
